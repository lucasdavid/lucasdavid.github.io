<!DOCTYPE html>
<html lang="en">
<head>
  <title>K-Means and Hierarchical Clustering – Lucas David</title>
  <meta charset="utf-8" />
<meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="image_src" type="image/png" href="img_path" />


<meta name="description" content="Efficient clustering algorithms implementations in TensorFlow and NumPy." />
<meta property="og:description" content="Efficient clustering algorithms implementations in TensorFlow and NumPy." />
<meta property="og:image" content="" />

<meta name="author" content="Lucas David" />


<meta property="og:title" content="K-Means and Hierarchical Clustering" />
<meta property="twitter:title" content="K-Means and Hierarchical Clustering" />


<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<link rel="alternate" type="application/rss+xml" title="Lucas David - my personal website/blog"
      href="/feed.xml" />

  
  
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-LG7FZ8VCHM"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-LG7FZ8VCHM');
	</script>


  
  <!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/style.css" />

</head>
<body>
  <nav id="mainNav" class="navbar navbar-light bg-white navbar-expand-lg d-print-none border-bottom border-light ">
  <div class="container-xl">
    <button class="navbar-toggler rounded-0 border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navbarTogglerDemo01"
      aria-controls="navbarTogglerDemo01" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <a class="navbar-brand fw-bold text-decoration-none p-1" href="/">Lucas David</a>

    <div class="collapse navbar-collapse" id="navbarTogglerDemo01">

      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
      </ul>
      <span class="navbar-text navbar-excerpt">
        K-Means and Hierarchical Clustering
      </span>
      <span class="navbar-text font-small ms-2 me-2 sr-none" aria-hidden="true">•</span>
      <ul class="navbar-nav mb-2 mb-lg-0 font-small">
        <li class="nav-item"><a href="/" class="nav-link fw-bold link-dark fs-6">Home</a></li>
        <li class="nav-item"><a href="/blog" class="nav-link fw-bold link-dark fs-6">Blog</a></li>
        <li class="nav-item"><a href="/publications" class="nav-link fw-bold link-dark fs-6">Publications</a></li>

        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle fw-bold link-dark fs-6" href="#" id="nbd-links-social" role="button"
            data-bs-toggle="dropdown" aria-expanded="false">
            Social
          </a>
          <ul class="dropdown-menu font-small dropdown-menu-end" aria-labelledby="nbd-links-social">
            <li><a class="dropdown-item text-decoration-none" target="_blank"
                href="https://github.com/lucasdavid">
                <i aria-label="GitHub" class="bi bi-github link-dark sr-none"></i>
                Github</a></li>
            <li><a class="dropdown-item text-decoration-none" target="_blank"
                href="https://www.linkedin.com/in/ld7">
                <i class="bi bi-linkedin text-primary sr-none"></i>
                Linkedin</a></li>

            <li itemscope itemtype="https://schema.org/Person">
              <a itemprop="sameAs" content="https://orcid.org/0000-0002-8793-7300" href="https://orcid.org/0000-0002-8793-7300"
                  target="orcid.widget"
                  rel="me noopener noreferrer"
                  class="dropdown-item text-decoration-none"
                >
                <img src="/assets/images/infra/32px-ORCID_iD.webp" alt="ORCID logo" class="sr-none" style="margin-bottom: 5px; width: 16px;">
                ORCID</a>
            </li>

            <li><a class="dropdown-item text-decoration-none" target="_blank"
                href="http://stackoverflow.com/users/2429640/lucasdavid">
                <i class="bi bi-code-slash link-dark sr-none"></i>
                Stackoverflow</a></li>
            <li><a class="dropdown-item text-decoration-none" target="_blank"
                href="https://youtube.com/channel/UC7IWeKUy4OSlC5ripcQGD6Q">
                <i class="bi bi-youtube text-danger sr-none"></i>
                Youtube</a></li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</nav>

  <div class="empty-v-space d-none d-xl-block" style="margin-bottom: 5vh"></div>
</div>
<div class="container-fluid mt-4">
  <div class="row">
    <div class="col-12 col-xl-3 col-xxl-2 offset-xxl-1">
      <div id="sidebar" class="">
  <div class="text-center">
    <a href="/" title="Home">
      <img src="/assets/images/infra/aloy-100.png" alt="Aloy, a character from Horizon Zero Dawn."
        class="img-fluid rounded-circle" style="width:100px" />
    </a>
    <p class="pt-2 font-small">
      
        <a href="mailto:mb37410l3@mozmail.com" class="text-decoration-none fw-bold">mb37410l3@mozmail.com</a>
      
    </p>
  </div>

  
</div>

    </div>
    <div id="table-of-contents-container-r" class="col-12 col-xl-3 col-xxl-2 order-xl-2">
      
      <div style="z-index: 0; font-size:0.8rem;">
        <div id="table-of-contents" class="font-small">
  <p class="border-bottom"><strong>Summary</strong></p>
  <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#datasets">Datasets</a>
<ul>
<li class="toc-entry toc-h3"><a href="#clusterdat">cluster.dat</a></li>
<li class="toc-entry toc-h3"><a href="#california">California</a></li>
<li class="toc-entry toc-h3"><a href="#tf-flowers">TF-Flowers</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#part-1-clustering-methods">Part-1: Clustering Methods</a>
<ul>
<li class="toc-entry toc-h3"><a href="#k-means">K-Means</a></li>
<li class="toc-entry toc-h3"><a href="#hierarchical-clustering">Hierarchical Clustering</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#part-2-dimensionality-reduction">Part-2: Dimensionality Reduction</a>
<ul>
<li class="toc-entry toc-h3"><a href="#k-means-1">K-Means</a></li>
<li class="toc-entry toc-h3"><a href="#hierarchical-clustering-1">Hierarchical Clustering</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#references">References</a></li>
</ul>
</div>

      </div>
      
    </div>
    <div class="col-12 col-xl-6">
      <article class="post mb-4">
        <header class="">
          <h1 id="postTitle" class="fw-bold">K-Means and Hierarchical Clustering</h1>
          <p class="right-align mb-2 text-muted fs-5">
            Efficient clustering algorithms implementations in TensorFlow and NumPy. <em>— June 11, 2021</em>
          </p>
          <div class="mb-4">
            <span class="badges-container">
  
    <a href="/blog/tag/ml"
       class="btn badge rounded-pill btn-dark text-bg-dark text-decoration-none"
       style="font-size: 0.8em;"
       type="button"
       role="button"
       >ML</a>
  
    <a href="/blog/tag/clustering"
       class="btn badge rounded-pill btn-dark text-bg-dark text-decoration-none"
       style="font-size: 0.8em;"
       type="button"
       role="button"
       >Clustering</a>
  
    <a href="/blog/tag/tensorflow"
       class="btn badge rounded-pill btn-dark text-bg-dark text-decoration-none"
       style="font-size: 0.8em;"
       type="button"
       role="button"
       >TensorFlow</a>
  
</span>

          </div>
        </header>
        <div class="article-content" style="margin-top: 4rem;">
          <p><span class="fs-1" style="line-height:0">T</span>his
post is based on an assignment submitted to a Machine Learning class
at Universidade Estadual de Campinas, and its challenges were equally divided among
Jonathan and I.</p>

<p>Here, our goal is to apply unsupervised learning methods to solve clustering and
dimensionality reduction in two distinct task.
We implemented the K-Means and Hierarchical Clustering algorithms (and their
evaluation metrics) from the ground up. Results are presented over three distinct
datasets, including a bonus color quantization example.</p>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#collapseSetup" aria-controls="collapseSetup" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show setup code</button>
</div>

<div class="language-python collapse highlighter-rouge" id="collapseSetup"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">TensorFlow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">TensorFlow_datasets</span> <span class="k">as</span> <span class="n">tfds</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ParameterGrid</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
  <span class="k">class</span> <span class="nc">cluster_dat</span><span class="p">:</span>
    <span class="n">k_init_method</span> <span class="o">=</span> <span class="s">'kpp'</span>
    <span class="n">k_max</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">repeats</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">tol</span> <span class="o">=</span> <span class="p">.</span><span class="mi">0001</span>

    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">source</span> <span class="o">=</span> <span class="s">'/content/drive/MyDrive/datasets/MO444/cluster.dat'</span>

  <span class="k">class</span> <span class="nc">cali</span><span class="p">:</span>
    <span class="n">k_init_method</span> <span class="o">=</span> <span class="s">'kpp'</span>
    <span class="n">k_max</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">repeats</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">tol</span> <span class="o">=</span> <span class="p">.</span><span class="mi">0001</span>

    <span class="n">sample_size</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>

  <span class="k">class</span> <span class="nc">tf_flowers</span><span class="p">:</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># k, actually
</span>    <span class="n">training_samples</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">tol</span> <span class="o">=</span> <span class="p">.</span><span class="mi">01</span>

    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="mi">8</span>
    <span class="n">image_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
    <span class="n">channels</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">image_sizes</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span>

  <span class="k">class</span> <span class="nc">run</span><span class="p">:</span>
    <span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s">"husl"</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="c1"># seed = 472
</span>    <span class="n">seed</span> <span class="o">=</span> <span class="mi">821</span>


<span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">Config</span><span class="p">.</span><span class="n">run</span><span class="p">.</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">((</span><span class="n">Config</span><span class="p">.</span><span class="n">run</span><span class="p">.</span><span class="n">seed</span><span class="o">//</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">41</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">"whitegrid"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_palette</span><span class="p">(</span><span class="n">Config</span><span class="p">.</span><span class="n">run</span><span class="p">.</span><span class="n">palette</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">split_dataset</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">,</span> <span class="n">test_size</span><span class="p">):</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
  <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

  <span class="n">train_indices</span><span class="p">,</span> <span class="n">test_indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">test_size</span><span class="o">*</span><span class="n">s</span><span class="p">):],</span>
                                 <span class="n">indices</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">test_size</span><span class="o">*</span><span class="n">s</span><span class="p">)])</span>

  <span class="k">return</span> <span class="nb">sum</span><span class="p">(((</span><span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
               <span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">test_indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
              <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">),</span> <span class="p">())</span>

<span class="k">def</span> <span class="nf">standardize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_stats</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="s">"""Standardize data based on its mean and standard-deviation.
  """</span>
  <span class="n">u</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
  <span class="k">if</span> <span class="n">center</span><span class="p">:</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">-</span><span class="n">u</span>

  <span class="k">if</span> <span class="n">scale</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">return_stats</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">inverse_standardize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">s</span>
  <span class="k">if</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">+</span><span class="n">u</span>
  <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">size_in_mb</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_prod</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span> <span class="o">/</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">visualize_clusters</span><span class="p">(</span><span class="o">*</span><span class="n">sets</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">6</span><span class="p">)):</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
      <span class="s">'x'</span><span class="p">:</span> <span class="n">features</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
      <span class="s">'y'</span><span class="p">:</span> <span class="n">features</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
      <span class="s">'cluster'</span><span class="p">:</span> <span class="p">[</span><span class="sa">f</span><span class="s">'cluster </span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s">'</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)],</span>
      <span class="s">'subset'</span><span class="p">:</span> <span class="p">[</span><span class="n">subset</span><span class="p">]</span> <span class="o">*</span> <span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">})</span>
    <span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">subset</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">sets</span>
  <span class="p">])</span>

  <span class="k">if</span> <span class="n">full</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">title</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

  <span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="n">m</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">sets</span><span class="p">}</span>
  <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'x'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'cluster'</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s">'subset'</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="n">markers</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="n">legend</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">full</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">visualize_images</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">rows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">cols</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="p">):</span>
  <span class="k">if</span> <span class="n">image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># many images
</span>      <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
      <span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span> <span class="ow">or</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="o">/</span> <span class="n">rows</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">ix</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)):</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">ix</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">visualize_images</span><span class="p">(</span>
          <span class="n">image</span><span class="p">[</span><span class="n">ix</span><span class="p">],</span>
          <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">title</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">ix</span> <span class="k">else</span> <span class="bp">None</span><span class="p">)</span>
      <span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
      <span class="k">return</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span> <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="datasets">Datasets</h2>

<p>In this section, we present the datasets used in this assignment.
They were selected considering their diverse nature, in order to visualize the behavior of clustering/dimensionality reduction techniques in different scenarios.</p>

<h3 id="clusterdat">cluster.dat</h3>

<p>This dataset was provided during class. It comprises 573 samples and 2 numeric features.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cluster_train</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">source</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">cluster_train</span><span class="p">,</span> <span class="n">cluster_test</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span>
  <span class="n">cluster_train</span><span class="p">,</span>
  <span class="n">test_size</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">test_size</span>
<span class="p">)</span>

<span class="n">cluster_s_train</span><span class="p">,</span> <span class="p">(</span><span class="n">c_u</span><span class="p">,</span> <span class="n">c_s</span><span class="p">)</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">return_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cluster_s_test</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">cluster_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv1" aria-controls="cv1" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv1"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Original Cluster.dat Dataset'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cluster_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cluster_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'crimson'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cluster_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cluster_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'crimson'</span><span class="p">);</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Standardized Cluster.dat Dataset'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cluster_s_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cluster_s_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'crimson'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cluster_s_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cluster_s_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'crimson'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">();</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/14_0.png" alt="The Cluster.dat Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">The Cluster.dat Dataset.</strong>

     (a) the features in their original value range, and (b) features were scaled in order to have mean 0 and standard deviation 1.
  </figcaption>


  </figure>
</div>

<h3 id="california">California</h3>

<p>The california housing dataset was constructed by collecting information over all block groups from the 1990 Census.
It comprises 20,640 samples and 9 features, associating the aforementioned blocks to the log of the median house value within them.
Finally, blocks on average contain 1425.5 individuals <a class="citation" href="#pace1997sparse">[1]</a>.</p>

<p>Features are:</p>

<ul>
  <li>MedInc: median income in block group;</li>
  <li>HouseAge: median house age in block group;</li>
  <li>AveRooms: average number of rooms per household;</li>
  <li>AveBedrms: average number of bedrooms per household;</li>
  <li>Population: block group population;</li>
  <li>AveOccup: average number of household members;</li>
  <li>Latitude: block group latitude;</li>
  <li>Longitude: block group longitude.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>

<span class="n">cali</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">cali_feature_names</span> <span class="o">=</span> <span class="n">cali</span><span class="p">.</span><span class="n">feature_names</span>

<span class="n">cali_x_train</span> <span class="o">=</span> <span class="n">cali</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)[:</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">sample_size</span><span class="p">]</span>
<span class="n">cali_y_train</span> <span class="o">=</span> <span class="n">cali</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)[:</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">sample_size</span><span class="p">]</span>

<span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">cali_x_test</span><span class="p">,</span> <span class="n">cali_y_train</span><span class="p">,</span> <span class="n">cali_y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span>
  <span class="n">cali_x_train</span><span class="p">,</span>
  <span class="n">cali_y_train</span><span class="p">,</span>
  <span class="n">test_size</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">test_size</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">cali_s_train</span><span class="p">,</span> <span class="p">(</span><span class="n">b_u</span><span class="p">,</span> <span class="n">b_s</span><span class="p">)</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">return_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cali_s_test</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">,</span> <span class="n">us</span><span class="o">=</span><span class="p">(</span><span class="n">b_u</span><span class="p">,</span> <span class="n">b_s</span><span class="p">))</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv2" aria-controls="cv2" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv2"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Original California Dataset'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cali_x_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cali_x_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cali_x_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cali_x_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">cali_feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">cali_feature_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Standardized California Dataset'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cali_s_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cali_s_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cali_s_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">cali_s_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">cali_feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">cali_feature_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">cali_x_train</span><span class="p">,</span> <span class="n">cali_x_test</span> <span class="o">=</span> <span class="n">cali_s_train</span><span class="p">,</span> <span class="n">cali_s_test</span>
<span class="k">del</span> <span class="n">cali_s_train</span><span class="p">,</span> <span class="n">cali_s_test</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/18_0.png" alt="The California Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">The California Dataset.</strong>

    (a) the features in their original value range, and (b) features were scaled in order to have mean 0 and standard deviation 1.
  </figcaption>


  </figure>
</div>

<h3 id="tf-flowers">TF-Flowers</h3>

<p>We utilize <a href="https://www.TensorFlow.org/datasets/catalog/tf_flowers">TF-Flowers</a> dataset to illustrate the application of K-Means in Color Quantization.
This dataset represents a multi-class (mono-label) image classification problem, and comprises 3,670 photographs of flowers associated with one of the following labels: <em>dandelion</em>, <em>daisy</em>, <em>tulips</em>, <em>sunflowers</em> or <em>roses</em>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocessing_fn</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
  <span class="n">current</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">image</span><span class="p">)[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">image_sizes</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">ratio</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">target</span> <span class="o">/</span> <span class="n">current</span><span class="p">))</span>
  <span class="n">new_sizes</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">current</span><span class="o">*</span><span class="n">ratio</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>

  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">new_sizes</span><span class="p">,</span> <span class="n">preserve_aspect_ratio</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize_with_crop_or_pad</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="o">*</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">image_sizes</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>

<span class="k">def</span> <span class="nf">prepare</span><span class="p">(</span><span class="n">ds</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">ds</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">buffer_size</span><span class="p">)</span>
            <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">preprocessing_fn</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
            <span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">load_tf_flowers</span><span class="p">():</span>
  <span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">),</span> <span class="n">info</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s">'tf_flowers'</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="s">'train[:50%]'</span><span class="p">,</span> <span class="s">'train[50%:]'</span><span class="p">],</span>
    <span class="n">with_info</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">as_supervised</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">shuffle_files</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

  <span class="n">train_ds</span> <span class="o">=</span> <span class="n">prepare</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>
  <span class="n">test_ds</span> <span class="o">=</span> <span class="n">prepare</span><span class="p">(</span><span class="n">test_ds</span><span class="p">)</span>

  <span class="n">train_ds</span><span class="p">.</span><span class="n">info</span> <span class="o">=</span> <span class="n">info</span>
  <span class="n">train_ds</span><span class="p">.</span><span class="n">int2str</span> <span class="o">=</span> <span class="n">info</span><span class="p">.</span><span class="n">features</span><span class="p">[</span><span class="s">'label'</span><span class="p">].</span><span class="n">int2str</span>

  <span class="k">return</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">test_ds</span>

<span class="n">flowers_train_set</span><span class="p">,</span> <span class="n">flowers_test_set</span> <span class="o">=</span> <span class="n">load_tf_flowers</span><span class="p">()</span>

<span class="n">images</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">flowers_train_set</span><span class="p">))</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">flowers_train_set</span><span class="p">.</span><span class="n">int2str</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">target</span><span class="p">]</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv3" aria-controls="cv3" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv3"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_images</span><span class="p">(</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">uint8</span><span class="p">),</span>
  <span class="n">labels</span><span class="p">,</span>
  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/23_0.jpg" alt="The TF-Flowers Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">The TF-Flowers Dataset.</strong>

    Samples were randomly drawn.
  </figcaption>


  </figure>
</div>

<h2 id="part-1-clustering-methods">Part-1: Clustering Methods</h2>

<h3 id="k-means">K-Means</h3>

<p>Our K-Means implementation was developed on top of the TensorFlow library, and was expressed in its primal optimization form <a class="citation" href="#wiki:K-means_clustering">[2]</a>.</p>

<p>Let:</p>

<ul>
  <li>$X$ be the set of observations</li>
  <li>$k\in\mathbb{Z}$ the number of clusters</li>
  <li>$C = \{C_1, C_2, \ldots, C_k\}$ a set of $k$ clusters,
represented by their respective “centers” $\{c_1, c_2, \ldots, c_k\}$</li>
</ul>

<p>A given sample $x\in X$ is said contained in cluster
$C_i\in C$ $\iff i=\text{argmin}_j ||x-c_j||^2$. That is, $x$ is closer to $c_i$ than to any other $c_j, \forall j\in [1, k] \setminus \{i\}$.</p>

<p>K-Means’s prime form can be described as a non-linear optimization problem over the cost function $J(X, C)$:</p>

\[\text{argmin}_C \sum_{i}^k \sum_{x\in C_i} \|x-c_i\|^2\]

<p>As this error is minimum when $c_i = \mu_i = \frac{1}{|C_i|}\sum_{x\in C_i} x$, we know the negative gradient $-\nabla J$ points out in the direction towards the centroids of the  clusters in $C$, and this function can be optimized using <em>Gradient Descent</em>:</p>

\[C^n := C^{n-1} - \lambda\nabla J\]

<p>Where $\lambda$ is the associated learning rate.</p>

<h4 id="algorithm">Algorithm</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kmeans_fit</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="p">.</span><span class="mi">001</span><span class="p">,</span>
    <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">report_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
  <span class="s">"""Learn the set of clusters that minimize the WSS loss function.

  Arguments
  ---------
  x: tf.Tensor (samples, features)
    samples from the dataset that we are studying
  c: tf.Variable (clusters, features)
    an initial set of clusters, used as starting point for the optimization process
  steps: int
    the number of optimization iterations
  lr: float
    the learning rate used to amortize the gradients
    in case batches of data are being passed
  tol: float
    minimum absolute loss variance between two consecutive
    iterations so converge is declared

  Returns
  -------
  tf.Tensor
    The list of clusters, a tensor of shape (clusters, features).
  """</span>
  <span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'learning_rate'</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Step 0'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

  <span class="n">p_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">kmeans_train_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">lr</span><span class="p">).</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">%</span> <span class="n">report_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="sa">f</span><span class="s">'Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

    <span class="n">diff_loss</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="n">p_loss</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">diff_loss</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">Early stopping as loss diff less than tol [</span><span class="si">{</span><span class="n">diff_loss</span><span class="p">:.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> &gt; </span><span class="si">{</span><span class="n">tol</span><span class="p">:.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">]'</span><span class="p">)</span>
      <span class="k">break</span>

    <span class="n">p_loss</span> <span class="o">=</span> <span class="n">loss</span>

  <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">%</span> <span class="n">report_every</span><span class="p">:</span>
    <span class="c1"># last step, if not reported yet
</span>    <span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="sa">f</span><span class="s">'Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">c</span>

<span class="k">def</span> <span class="nf">kmeans_train_step</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">:</span>
  <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">KMeansMetrics</span><span class="p">.</span><span class="n">WCSS</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

  <span class="n">dldc</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">c</span><span class="p">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="n">dldc</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">kmeans_test_step</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
  <span class="n">k</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">shape</span>

  <span class="n">d</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">s</span> <span class="o">=</span> <span class="n">KMeansMetrics</span><span class="p">.</span><span class="n">samples_per_cluster</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">wss_</span> <span class="o">=</span> <span class="n">KMeansMetrics</span><span class="p">.</span><span class="n">WCSS</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">bss_</span> <span class="o">=</span> <span class="n">KMeansMetrics</span><span class="p">.</span><span class="n">BCSS</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">sil_</span> <span class="o">=</span> <span class="n">KMeansMetrics</span><span class="p">.</span><span class="n">silhouette</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">wc_sil_</span> <span class="o">=</span> <span class="n">KMeansMetrics</span><span class="p">.</span><span class="n">wc_avg_silhouette</span><span class="p">(</span><span class="n">sil_</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
    <span class="p">(</span><span class="s">'Loss'</span><span class="p">,</span> <span class="s">'WCSS'</span><span class="p">,</span> <span class="s">'BCSS'</span><span class="p">,</span> <span class="s">'Silhouette'</span><span class="p">,</span> <span class="s">'WC Silhouette'</span><span class="p">,</span> <span class="s">'Samples'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">wss_</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">wss_</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">bss_</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">sil_</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">wc_sil_</span><span class="p">).</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span>
  <span class="p">))</span>

<span class="k">def</span> <span class="nf">kmeans_report_evaluation</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
  <span class="n">report</span> <span class="o">=</span> <span class="n">kmeans_test_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

  <span class="k">print</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
  <span class="n">lpad</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">report</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span>
  <span class="n">rpad</span> <span class="o">=</span> <span class="mi">12</span>

  <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">report</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'  </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s">'</span><span class="p">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">lpad</span><span class="p">),</span> <span class="s">'='</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)).</span><span class="n">rjust</span><span class="p">(</span><span class="n">rpad</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kmeans_search</span><span class="p">(</span>
  <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
  <span class="n">k_max</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
  <span class="n">init</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'kpp'</span><span class="p">,</span>
  <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
  <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="p">.</span><span class="mi">001</span><span class="p">,</span>
  <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
  <span class="n">repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
  <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">:</span>
  <span class="s">"""N-Repeated Line-Search for K Parameter Optimization.

  Arguments
  ---------
  x: tf.Tensor (samples, features)
    samples from the dataset that we are studying
  k_max: int
    maximum number of clusters used when searching
  init: str
    initialization method used.
    Options are:
      - normal: normally distributed clusters, following the training set's distribution.
      - uniform: uniformally distributed clusters, following the training set's distribution.
      - random_points: draw points from the training set and use them as clusters.
      - kpp: k-means++ algorithm

  steps: int
    the number of optimization iterations
  lr: float
    the learning rate used to amortize the gradients
    in case batches of data are being passed
  tol: float
    minimum absolute loss variance between two consecutive
    iterations so converge is declared

  Returns
  -------
    pd.DataFrame
      The search results report.
  """</span>
  <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="n">init</span> <span class="o">=</span> <span class="n">get_k_init_fn_by_name</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">k_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'k: </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">, performing </span><span class="si">{</span><span class="n">repeats</span><span class="si">}</span><span class="s"> tests'</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
      <span class="n">clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">init</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s">'ck</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
      <span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">metrics</span> <span class="o">=</span> <span class="n">kmeans_test_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>

      <span class="n">results</span> <span class="o">+=</span> <span class="p">[{</span><span class="s">'k'</span><span class="p">:</span> <span class="n">k</span><span class="p">,</span> <span class="s">'repetition'</span><span class="p">:</span> <span class="n">r</span><span class="p">,</span> <span class="o">**</span><span class="n">metrics</span><span class="p">}]</span>

      <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s">'.'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">''</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="n">repeats</span><span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kmeans_predict</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
  <span class="s">"""Predict cluster matching for dataset {x} based on pre-trained clusters {c}.
  """</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">d</span>
</code></pre></div></div>

<h4 id="evaluation-metrics">Evaluation Metrics</h4>

<p>In this section, we describe the metrics employed to evaluate K-Means, as well as their actual python implementations.</p>

<ul>
  <li>
    <p>Within Cluster Sum of Squares (WCSS)</p>

    <p>Computes the sum (macro average, really) of distances between each sample and its respective cluster’s centroid <a class="citation" href="#kriegel2017">[3]</a>.
This function (K-Means primal form) is used as loss function in our opt function.</p>

    <p>Def: $Σ_i^k Σ_{x \in c_i} ||x - \bar{x}_{c_i}||^2$</p>
  </li>
  <li>
    <p>Between Cluster Sum of Squares (BCSS)</p>

    <p>Computes the sum (macro average, really) distance between each sample $x\in c_i$ to the centroids of the clusters $c_k\in C\setminus c_i$ <a class="citation" href="#kriegel2017">[3]</a>.</p>

    <p>Def: $Σ_i^k Σ_{x \in X \setminus c_i} ||x - \bar{x}_{c_i}||^2$</p>
  </li>
  <li>
    <p>Silhouette <a class="citation" href="#pedregosa2011">[4]</a></p>

    <p>In our <em>silhouette</em> implementation, we used the one-hot encoding representation to select the corresponding samples of each cluster when computing avg. inter/intra cluster distance between samples $\{x_0, x_1, \ldots, x_n\}$ and clusters $\{c_0, c_1,\ldots, l_k\}$:</p>

\[\begin{align}
D &amp;= \begin{bmatrix}
  d_{00} &amp; d_{01} &amp; d_{02} &amp; \ldots &amp; d_{0n} \\
  d_{10} &amp; d_{11} &amp; d_{12} &amp; \ldots &amp; d_{1n} \\
  \ldots \\
  d_{n0} &amp; d_{n1} &amp; d_{n2} &amp; \ldots &amp; d_{nn} \\
\end{bmatrix} \\
y &amp;= \begin{bmatrix}
  0 &amp; 1 &amp; 2 &amp; 0 &amp; 1 &amp; 2 &amp; \ldots
\end{bmatrix} \\
D \cdot \text{onehot}(y) &amp;= \begin{bmatrix}
  \sum_i d_{0,i}[y_i=0] &amp; \sum_i d_{0,i}[y_i=1] &amp; \ldots &amp; \sum_i d_{0,i}[y_i=k]\\
  \sum_i d_{1,i}[y_i=0] &amp; \sum_i d_{1,i}[y_i=1] &amp; \ldots &amp; \sum_i d_{1,i}[y_i=k]\\
  \ldots\\
  \sum_i d_{n,i}[y_i=0] &amp; \sum_i d_{n,i}[y_i=1] &amp; \ldots &amp; \sum_i d_{n,i}[y_i=k]\\
\end{bmatrix}
\end{align}\]
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
  <span class="s">"""Calculate the squared distance from each
    point in {x} to each point in {c}.
  """</span>
  <span class="n">s</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
  <span class="n">k</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">shape</span>

  <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">tf</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">...]</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">...]</span>

  <span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">d</span>

<span class="k">class</span> <span class="nc">KMeansMetrics</span><span class="p">:</span>
  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">WCSS</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="s">"""Within Cluster Sum of Squares.

    Note:
      This function returns a vector with the distances between points and their
      respective clusters --- without adding them ---, as `tf.GradientTape#gradients`
      will automatically add these factors together to form the gradient.

      We choose this formulation so this same code can be conveniently averaged (instead of summed)
      during evaluation, and behave consistently between sets with different cardinality (e.g. train, test).

    """</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">d</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">BCSS</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="s">"""Between Cluster Sum of Squares.
    """</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">di</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">di</span>

    <span class="k">return</span> <span class="n">db</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">silhouette</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="s">"""Silhouette score as defined by Scikit-learn.
    """</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">du</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">divide_no_nan</span><span class="p">(</span>
      <span class="n">d</span> <span class="o">@</span> <span class="n">h</span><span class="p">,</span>
      <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">du</span><span class="p">[</span><span class="n">h</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">du</span><span class="p">[</span><span class="n">h</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (k-1), as one of these distances was selected into `a`.
</span>    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>          <span class="c1"># using `tf.reduce_min` as sklearn defines Silhouette's
</span>                                           <span class="c1"># `b` as "nearest-cluster distance" [2].
</span>    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">divide_no_nan</span><span class="p">(</span>
      <span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">,</span>
      <span class="n">tf</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="p">)</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">samples_per_cluster</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="n">C_i</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">C_i</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">C_i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">C_i</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">C_i</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">C_i</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">C_i</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="n">c</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">C_i</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">C_i</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">C_i</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">wc_avg_silhouette</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">h</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sc</span>
</code></pre></div></div>

<h4 id="clusters-initialization">Clusters Initialization</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">normal_clusters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="s">"""Normal clusters.

  Draw random clusters that follow the same distribution as the training set `x`.

  """</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="n">u</span><span class="p">,</span> <span class="n">st</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
           <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">f</span><span class="p">])</span> <span class="o">*</span> <span class="n">st</span> <span class="o">+</span> <span class="n">u</span>


<span class="k">def</span> <span class="nf">uniform_clusters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="s">"""Uniform clusters.

  Draw uniformly random clusters that are strictly contained within the min and max
  values present in the training set `x`. Useful when drawing image pixels (see
  Application over The TF-Flowers Dataset section for usage).

  """</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">f</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">random_points_clusters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="s">"""Random Points clusters.

  Draw clusters that coincide with the points in the training set `x`.

  """</span>
  <span class="n">samples</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">k</span><span class="p">],</span> <span class="n">minval</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">dtypes</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">kpp_clusters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'CPU:0'</span><span class="p">):</span>
  <span class="s">"""K-Means++ clusters.

  Draw clusters using the k-means++ procedure.

  Note: this section relies heavely on numpy, as we were unable to implement the
  function `np.random.choice(..., p=[0.1, 0.2, ...])` in TensorFlow. We therefore
  force the code execution of this section in the CPU.
  You can override this behavior by passing `device='GPU:0'` as a function argument.

  """</span>
  <span class="n">s</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>

  <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">k_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
      <span class="n">d_xc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">d_xc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">d_xc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">pr</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">divide_no_nan</span><span class="p">(</span>
        <span class="n">d_xc</span><span class="p">,</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">d_xc</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="n">ci</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="n">pr</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span>
      <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">concat</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">ci</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_k_init_fn_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">_clusters'</span><span class="p">]</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv4" aria-controls="cv4" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv4"><div class="highlight"><pre class="highlight"><code><span class="n">initializations</span> <span class="o">=</span> <span class="p">(</span><span class="n">normal_clusters</span><span class="p">,</span>
                   <span class="n">uniform_clusters</span><span class="p">,</span>
                   <span class="n">random_points_clusters</span><span class="p">,</span>
                   <span class="n">kpp_clusters</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="n">ini</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">initializations</span><span class="p">):</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">ini</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
  <span class="n">p_tr</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
  <span class="n">p_te</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

  <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">initializations</span><span class="p">),</span> <span class="n">ix</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">visualize_clusters</span><span class="p">(</span>
    <span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">p_tr</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">p_te</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s">'clusters'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">),</span>  <span class="c1"># labels for clusters are trivial (0, 1, 2, ...)
</span>    <span class="n">title</span><span class="o">=</span><span class="n">ini</span><span class="p">.</span><span class="n">__name__</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">full</span><span class="o">=</span><span class="bp">False</span>
  <span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">();</span>
</code></pre></div></div>

<div style="" class="w-lg-100 w-xl-175 text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/35_0.png" alt="Effect of initialization procedure over the initial state of the model." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Effect of initialization procedure over the initial state of the model.</strong>

    Drawing points from the dataset itself (<code>random_points_clusters</code>) produces better results than uniform or normal clusters, while <code>kpp_clusters</code> results in an almost perfect clustering from the start.
  </figcaption>


  </figure>
</div>

<p>The <code class="language-plaintext highlighter-rouge">normal_clusters</code> initialization procedure considers the mean and standard deviation of the training set’s distribution, which means points drawn from this procedure will belong to the set’s distribution and assume reasonable values in each feature.
For datasets with complex shapes (with holes close to its features’ average values), this method might create unreasonable clusters, which lie on empty sections of the dimensional space. In the example above, we see clusters lying in between the data masses.</p>

<p>The <code class="language-plaintext highlighter-rouge">uniform</code> initialization behaves similarly to <code class="language-plaintext highlighter-rouge">random_clusters</code>, but it is ensured to always draw samples with feature values within their respective valid intervals.</p>

<p>On the other hand, <code class="language-plaintext highlighter-rouge">random_points_clusters</code> draws points from the training set itself, which will invariantly assume valid values in each feature, being valid cluster’s centroid candidates. Its drawback lies on the uniform selection procedure itself: sampling datasets containing unbalanced masses will likely result in clusters being drawn from a same mass.</p>

<p>Finally, K-Means++ <a class="citation" href="#arthur2006k">[5]</a> seems to already separate the data masses correctly from the start. K-Means will mearly move these points to their respective data masses’ centroids.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ctr</span> <span class="o">=</span> <span class="n">cluster_train</span> <span class="o">*</span> <span class="n">c_s</span> <span class="o">+</span> <span class="n">c_u</span>
<span class="n">cte</span> <span class="o">=</span> <span class="n">cluster_test</span> <span class="o">*</span> <span class="n">c_s</span> <span class="o">+</span> <span class="n">c_u</span>

<span class="n">c0</span> <span class="o">=</span> <span class="n">kpp_clusters</span><span class="p">(</span><span class="n">ctr</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">c1</span> <span class="o">=</span> <span class="n">kpp_clusters</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">p0_train</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">ctr</span><span class="p">,</span> <span class="n">c0</span><span class="p">)</span>
<span class="n">p0_test</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cte</span><span class="p">,</span> <span class="n">c0</span><span class="p">)</span>

<span class="n">p1_train</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">c1</span><span class="p">)</span>
<span class="n">p1_test</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">c1</span><span class="p">)</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv5" aria-controls="cv5" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-py collapse highlighter-rouge" id="cv5"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">ctr</span><span class="p">,</span> <span class="n">p0_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">cte</span><span class="p">,</span> <span class="n">p0_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">c0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s">'clusters'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">),</span>         <span class="c1"># labels for clusters are trivial (0, 1, 2, ...)
</span>  <span class="n">title</span><span class="o">=</span><span class="s">'Original Data Initial Clustering'</span><span class="p">,</span>
  <span class="n">full</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
  <span class="n">legend</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">p1_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">p1_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">c1</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s">'clusters'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">),</span>         <span class="c1"># labels for clusters are trivial (0, 1, 2, ...)
</span>  <span class="n">title</span><span class="o">=</span><span class="s">'Standardized Data Initial Clustering'</span><span class="p">,</span>
  <span class="n">full</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
  <span class="n">legend</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">();</span>

<span class="k">del</span> <span class="n">ctr</span><span class="p">,</span> <span class="n">cte</span><span class="p">,</span> <span class="n">c0</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">p0_train</span><span class="p">,</span> <span class="n">p0_test</span><span class="p">,</span> <span class="n">p1_train</span><span class="p">,</span> <span class="n">p1_test</span>
</code></pre></div></div>

<div style="" class="w-lg-100 w-xl-175 text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/37_0.png" alt="Effect of data standardization over K-Means's initial configuration." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Effect of data standardization over K-Means's initial configuration.</strong>

    Without standardization, samples are not correctly aggregated because of the different proportions of each axis.
  </figcaption>


  </figure>
</div>

<p>In the example above, the unstandardized feature $y$ ranged within the interval $[0, 30]$, which profoundly affected the $l^2$ distance.
Conversely, variations in feature $x\in [250, 3750]$ caused a smaller impact on clustering configuration.
In the second scatterplot, we notice all features belonging to the same interval, and contributing similarly to the distance function $l^2$.</p>

<h4 id="application-over-the-clusterdat-dataset">Application over The Cluster.dat Dataset</h4>

<p>An interesting application of clustering is image compression through <em>color quantization</em>.
In this procedure, the RGB pixels in an image are clustered into $k$ groups, comprising the color book.
The image can then be “compressed” by replacing each pixel by its cluster’s centroid’s identifier,
which effectively reduces three floating point numbers to a single unsigned integer
(plus the memory necessary to store the color book).</p>

<h5 id="searching-k">Searching K</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">kmeans_search</span><span class="p">(</span>
  <span class="n">cluster_train</span><span class="p">,</span>
  <span class="n">k_max</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">k_max</span><span class="p">,</span>
  <span class="n">init</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">k_init_method</span><span class="p">,</span>
  <span class="n">repeats</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">repeats</span><span class="p">,</span>
  <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>k: 2, performing 100 tests
....................................................................................................
k: 3, performing 100 tests
....................................................................................................
k: 4, performing 100 tests
....................................................................................................
k: 5, performing 100 tests
....................................................................................................
k: 6, performing 100 tests
....................................................................................................
k: 7, performing 100 tests
....................................................................................................
k: 8, performing 100 tests
....................................................................................................
k: 9, performing 100 tests
....................................................................................................
k: 10, performing 100 tests
....................................................................................................
CPU <span class="nb">times</span>: user 4min, sys: 1.32 s, total: 4min 2s
Wall <span class="nb">time</span>: 3min 53s
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">report</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'k'</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
  <tr>
    <th>k</th>
    <th>repetition</th>
    <th>Loss</th>
    <th>WCSS</th>
    <th>BCSS</th>
    <th>Silhouette</th>
    <th>WC Silhouette</th>
    <th>Samples</th>
  </tr></thead>
<tbody>
  <tr>
    <td>2</td>
    <td>49.5</td>
    <td>576.63</td>
    <td>1.12</td>
    <td>5.81</td>
    <td>0.63</td>
    <td>0.32</td>
    <td>[295.93, 220.07]</td>
  </tr>
  <tr>
    <td>3</td>
    <td>49.5</td>
    <td>139.47</td>
    <td>0.27</td>
    <td>11.89</td>
    <td>0.88</td>
    <td>0.29</td>
    <td>[176.21, 166.32, 173.47]</td>
  </tr>
  <tr>
    <td>4</td>
    <td>49.5</td>
    <td>110.74</td>
    <td>0.21</td>
    <td>15.67</td>
    <td>0.72</td>
    <td>0.18</td>
    <td>[143.63, 137.19, 127.55, 107.63]</td>
  </tr>
  <tr>
    <td>5</td>
    <td>49.5</td>
    <td>92.67</td>
    <td>0.18</td>
    <td>19.90</td>
    <td>0.66</td>
    <td>0.13</td>
    <td>[115.62, 108.89, 113.64, 95.02, 82.83]</td>
  </tr>
  <tr>
    <td>6</td>
    <td>49.5</td>
    <td>78.08</td>
    <td>0.15</td>
    <td>23.91</td>
    <td>0.62</td>
    <td>0.10</td>
    <td>[96.23, 96.44, 86.15, 86.56, 76.25, 74.37]</td>
  </tr>
  <tr>
    <td>7</td>
    <td>49.5</td>
    <td>66.92</td>
    <td>0.13</td>
    <td>27.78</td>
    <td>0.59</td>
    <td>0.08</td>
    <td>[80.53, 80.69, 83.48, 72.83, 69.0, 65.91, 63.56]</td>
  </tr>
  <tr>
    <td>8</td>
    <td>49.5</td>
    <td>57.72</td>
    <td>0.11</td>
    <td>31.94</td>
    <td>0.58</td>
    <td>0.07</td>
    <td>[74.07, 71.94, 71.97, 63.15, 63.07, 59.2, 57.1...</td>
  </tr>
  <tr>
    <td>9</td>
    <td>49.5</td>
    <td>51.29</td>
    <td>0.10</td>
    <td>35.79</td>
    <td>0.56</td>
    <td>0.06</td>
    <td>[66.08, 65.78, 59.17, 56.12, 57.82, 55.57, 52....</td>
  </tr>
  <tr>
    <td>10</td>
    <td>49.5</td>
    <td>45.16</td>
    <td>0.09</td>
    <td>40.29</td>
    <td>0.54</td>
    <td>0.05</td>
    <td>[55.91, 55.6, 56.11, 54.11, 52.36, 51.56, 48.5...</td>
  </tr>
</tbody>
</table>
</div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv6" aria-controls="cv6" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv6"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Within-Cluster Avg Squared Error'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'WCSS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Between-Cluster Sum Squared Error'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'BCSS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Avg Silhouette'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Silhouette'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Within-Cluster Avg Silhouette'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'WC Silhouette'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">();</span>
</code></pre></div></div>

<div style="" class="w-lg-100 w-xl-175 text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/43_0.png" alt="Clustering metrics for each choice of number of clusters k, considering the Cluster.dat dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Clustering metrics for each choice of number of clusters k, considering the Cluster.dat dataset.</strong>

    The highest decrease in WCSS is observed when using exactly 3 clusters, hence this is the optimal k according to the Elbow technique. Maximum Average Sihouette is also observed when $k=3$.
  </figcaption>


  </figure>
</div>

<h5 id="training">Training</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_k</span> <span class="o">=</span> <span class="n">report</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'k'</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">Silhouette</span><span class="p">.</span><span class="n">idxmax</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Best K (highest Silhouette) found: </span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Best K (highest Silhouette) found: 3
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">normal_clusters</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">best_k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s">'ck</span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_fit</span><span class="p">(</span>
  <span class="n">cluster_train</span><span class="p">,</span>
  <span class="n">clusters</span><span class="p">,</span>
  <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
  <span class="n">tol</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cluster_dat</span><span class="p">.</span><span class="n">tol</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 0
  Loss          <span class="o">=</span>     766.6576
  WCSS          <span class="o">=</span>       1.4858
  BCSS          <span class="o">=</span>       8.0952
  Silhouette    <span class="o">=</span>       0.4539
  WC Silhouette <span class="o">=</span>       0.1513
  Samples       <span class="o">=</span> <span class="o">[</span>225 178 113]
Step 10
  Loss          <span class="o">=</span>     136.2397
  WCSS          <span class="o">=</span>        0.264
  BCSS          <span class="o">=</span>      11.5245
  Silhouette    <span class="o">=</span>       0.8801
  WC Silhouette <span class="o">=</span>       0.2934
  Samples       <span class="o">=</span> <span class="o">[</span>252 151 113]
Step 20
  Loss          <span class="o">=</span>      135.358
  WCSS          <span class="o">=</span>       0.2623
  BCSS          <span class="o">=</span>      11.8682
  Silhouette    <span class="o">=</span>       0.8801
  WC Silhouette <span class="o">=</span>       0.2934
  Samples       <span class="o">=</span> <span class="o">[</span>252 151 113]

Early stopping as loss diff less than tol <span class="o">[</span>0.0001 <span class="o">&gt;</span> 0.0001]
Step 27
  Loss          <span class="o">=</span>     135.3553
  WCSS          <span class="o">=</span>       0.2623
  BCSS          <span class="o">=</span>      11.8859
  Silhouette    <span class="o">=</span>       0.8801
  WC Silhouette <span class="o">=</span>       0.2934
  Samples       <span class="o">=</span> <span class="o">[</span>252 151 113]
</code></pre></div></div>

<h5 id="evaluation">Evaluation</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_train</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="n">best_k</span><span class="p">)</span>  <span class="c1"># clusters tags are trivial: [0, 1, 2, ...]
</span>
<span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Train'</span><span class="p">,</span> <span class="n">cluster_train</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Test'</span><span class="p">,</span> <span class="n">cluster_test</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train
  Loss          <span class="o">=</span>     135.3553
  WCSS          <span class="o">=</span>       0.2623
  BCSS          <span class="o">=</span>      11.8859
  Silhouette    <span class="o">=</span>       0.8801
  WC Silhouette <span class="o">=</span>       0.2934
  Samples       <span class="o">=</span> <span class="o">[</span>252 151 113]
Test
  Loss          <span class="o">=</span>      17.3371
  WCSS          <span class="o">=</span>       0.3042
  BCSS          <span class="o">=</span>       12.609
  Silhouette    <span class="o">=</span>        0.872
  WC Silhouette <span class="o">=</span>       0.2907
  Samples       <span class="o">=</span>   <span class="o">[</span>21 19 17]
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv7" aria-controls="cv7" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv7"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">p_clusters</span><span class="p">,</span> <span class="s">'clusters'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/49_0.png" alt="K-Means Clustering over Cluster.dat Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">K-Means Clustering over Cluster.dat Dataset.</strong>

    Cluster's centroids quickly shift torwards the middle of the data masses, and few to no errors are made.
  </figcaption>


  </figure>
</div>

<h5 id="discussions">Discussions</h5>

<p>The search strategy found the correct underlying structure of the data ($K=3$).
With it, K-Means was able to perfecly separate the data.
The centroids of the clusters are seemly positioned on the center of each data mass.</p>

<p>As the train-test subsets were split through random selection, the data distributions from these sets are fairly similar.
Therefore, the K-Means produced similar results for all metrics associated (WCSS, BCSS and Silhouette).</p>

<p>A few points from the test set stand out, being the fartherest from the centroid of their clusters (bottom samples of clusters 1 and 2).  For cluster 1, two samples are close to the decision boundary between cluster 0 and 1, in which each is assigned a different label.
As for cluster 2, the three outlying samples are still correctly labeled.
Further inspection — and information around the problem domain — is needed in order to verify if these samples are indeed exceptional cases or merely noise during the capturing procedure.</p>

<h4 id="application-over-the-california-dataset">Application over The California Dataset</h4>

<h5 id="searching-k-1">Searching K</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">kmeans_search</span><span class="p">(</span>
  <span class="n">cali_x_train</span><span class="p">,</span>
  <span class="n">k_max</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">k_max</span><span class="p">,</span>
  <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
  <span class="n">repeats</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">repeats</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>k: 2, performing 100 tests
....................................................................................................
k: 3, performing 100 tests
....................................................................................................
k: 4, performing 100 tests
....................................................................................................
k: 5, performing 100 tests
....................................................................................................
k: 6, performing 100 tests
....................................................................................................
k: 7, performing 100 tests
....................................................................................................
k: 8, performing 100 tests
....................................................................................................
k: 9, performing 100 tests
....................................................................................................
k: 10, performing 100 tests
....................................................................................................
CPU <span class="nb">times</span>: user 12min 8s, sys: 2.56 s, total: 12min 11s
Wall <span class="nb">time</span>: 11min 44s
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">report</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'k'</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>
</code></pre></div></div>

<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
  <tr>
    <th>k</th>
    <th>repetition</th>
    <th>Loss</th>
    <th>WCSS</th>
    <th>BCSS</th>
    <th>Silhouette</th>
    <th>WC Silhouette</th>
    <th>Samples</th>
  </tr></thead>
<tbody>
  <tr>
    <td>2</td>
    <td>49.5</td>
    <td>2985.78</td>
    <td>6.64</td>
    <td>18.13</td>
    <td>0.36</td>
    <td>0.18</td>
    <td>[259.2, 190.8]</td>
  </tr>
  <tr>
    <td>3</td>
    <td>49.5</td>
    <td>2543.88</td>
    <td>5.65</td>
    <td>37.92</td>
    <td>0.35</td>
    <td>0.12</td>
    <td>[182.89, 133.99, 133.12]</td>
  </tr>
  <tr>
    <td>4</td>
    <td>49.5</td>
    <td>2270.23</td>
    <td>5.04</td>
    <td>69.53</td>
    <td>0.37</td>
    <td>0.09</td>
    <td>[141.5, 105.96, 95.41, 107.13]</td>
  </tr>
  <tr>
    <td>5</td>
    <td>49.5</td>
    <td>2052.74</td>
    <td>4.56</td>
    <td>91.41</td>
    <td>0.37</td>
    <td>0.07</td>
    <td>[109.45, 98.78, 91.96, 73.3, 76.51]</td>
  </tr>
  <tr>
    <td>6</td>
    <td>49.5</td>
    <td>1863.19</td>
    <td>4.14</td>
    <td>107.14</td>
    <td>0.38</td>
    <td>0.06</td>
    <td>[96.67, 78.08, 66.52, 67.57, 71.96, 69.2]</td>
  </tr>
  <tr>
    <td>7</td>
    <td>49.5</td>
    <td>1738.49</td>
    <td>3.86</td>
    <td>151.44</td>
    <td>0.38</td>
    <td>0.05</td>
    <td>[87.26, 70.27, 66.63, 57.43, 60.75, 54.7, 52.96]</td>
  </tr>
  <tr>
    <td>8</td>
    <td>49.5</td>
    <td>1621.18</td>
    <td>3.60</td>
    <td>160.81</td>
    <td>0.35</td>
    <td>0.04</td>
    <td>[71.36, 53.04, 58.04, 54.13, 53.49, 55.07, 54....</td>
  </tr>
  <tr>
    <td>9</td>
    <td>49.5</td>
    <td>1534.87</td>
    <td>3.41</td>
    <td>201.23</td>
    <td>0.35</td>
    <td>0.04</td>
    <td>[68.72, 51.51, 53.42, 44.84, 51.37, 45.14, 47....</td>
  </tr>
  <tr>
    <td>10</td>
    <td>49.5</td>
    <td>1459.060</td>
    <td>3.24</td>
    <td>218.63</td>
    <td>0.33</td>
    <td>0.03</td>
    <td>[63.48, 46.85, 43.4, 40.76, 44.69, 41.34, 40.2...</td>
  </tr>
</tbody>
</table>
</div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv8" aria-controls="cv8" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv8"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Within-Cluster Avg Squared Error'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'WCSS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Between-Cluster Sum Squared Error'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'BCSS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Avg Silhouette'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Silhouette'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Within-Cluster Avg Silhouette'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'WC Silhouette'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">();</span>
</code></pre></div></div>

<div style="" class="w-lg-100 w-xl-175 text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/55_0.png" alt="Clustering metrics for each choice of number of clusters k, considering the California dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Clustering metrics for each choice of number of clusters k, considering the California dataset.</strong>

    The WCSS graph does not show any "elbow". The highest Silhouette occurs for 2 clusters.
  </figcaption>


  </figure>
</div>

<h5 id="training-1">Training</h5>

<p>Although the Avg. and Within-Cluster Avg. Silhouette curves point $k=6$ as the best (on average) parameter, WCSS and BCSS show that a large quantity of the system’s total distance error could still be transfered from the within-distance component to the between-distance one by increasing the $k$ parameter.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_k</span> <span class="o">=</span> <span class="n">report</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'k'</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">Silhouette</span><span class="p">.</span><span class="n">idxmax</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Manually selected K: </span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Manually selected K: 6
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">normal_clusters</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">best_k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s">'ck</span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_fit</span><span class="p">(</span>
  <span class="n">cali_x_train</span><span class="p">,</span>
  <span class="n">clusters</span><span class="p">,</span>
  <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
  <span class="n">tol</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">tol</span><span class="p">,</span>
  <span class="n">report_every</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 0
  Loss          <span class="o">=</span>     3919.007
  WCSS          <span class="o">=</span>       8.7089
  BCSS          <span class="o">=</span>      83.3113
  Silhouette    <span class="o">=</span>       0.0903
  WC Silhouette <span class="o">=</span>       0.0151
  Samples       <span class="o">=</span> <span class="o">[</span>126 132  15  97  50  30]
Step 25
  Loss          <span class="o">=</span>    2086.1292
  WCSS          <span class="o">=</span>       4.6358
  BCSS          <span class="o">=</span>       75.879
  Silhouette    <span class="o">=</span>       0.3722
  WC Silhouette <span class="o">=</span>        0.062
  Samples       <span class="o">=</span> <span class="o">[</span>152  77  16 155  39  11]
Step 50
  Loss          <span class="o">=</span>    1901.8014
  WCSS          <span class="o">=</span>       4.2262
  BCSS          <span class="o">=</span>      77.6798
  Silhouette    <span class="o">=</span>       0.3968
  WC Silhouette <span class="o">=</span>       0.0661
  Samples       <span class="o">=</span> <span class="o">[</span>144  73  13 148  45  27]
Step 75
  Loss          <span class="o">=</span>     1824.202
  WCSS          <span class="o">=</span>       4.0538
  BCSS          <span class="o">=</span>      80.4515
  Silhouette    <span class="o">=</span>       0.4082
  WC Silhouette <span class="o">=</span>        0.068
  Samples       <span class="o">=</span> <span class="o">[</span>141  71  11 152  49  26]
Step 100
  Loss          <span class="o">=</span>    1794.4468
  WCSS          <span class="o">=</span>       3.9877
  BCSS          <span class="o">=</span>      84.4598
  Silhouette    <span class="o">=</span>       0.4106
  WC Silhouette <span class="o">=</span>       0.0684
  Samples       <span class="o">=</span> <span class="o">[</span>139  71  10 155  49  26]
</code></pre></div></div>

<h5 id="evaluation-1">Evaluation</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_train</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="n">best_k</span><span class="p">)</span>  <span class="c1"># clusters tags are trivial: [0, 1, 2, ...]
</span>
<span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Train'</span><span class="p">,</span> <span class="n">cali_x_train</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Test'</span><span class="p">,</span> <span class="n">cali_x_test</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train
  Loss          <span class="o">=</span>    1794.4468
  WCSS          <span class="o">=</span>       3.9877
  BCSS          <span class="o">=</span>      84.4598
  Silhouette    <span class="o">=</span>       0.4106
  WC Silhouette <span class="o">=</span>       0.0684
  Samples       <span class="o">=</span> <span class="o">[</span>139  71  10 155  49  26]
Test
  Loss          <span class="o">=</span>      189.131
  WCSS          <span class="o">=</span>       3.7826
  BCSS          <span class="o">=</span>      81.9574
  Silhouette    <span class="o">=</span>       0.4865
  WC Silhouette <span class="o">=</span>       0.0811
  Samples       <span class="o">=</span> <span class="o">[</span>16  8  1 18  5  2]
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv9" aria-controls="cv9" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv9"><div class="highlight"><pre class="highlight"><code><span class="n">e</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">),</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">),</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">clusters</span><span class="p">),</span> <span class="n">p_clusters</span><span class="p">,</span> <span class="s">'clusters'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/61_0.png" alt="K-Means clustering over California Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">K-Means clustering over California Dataset.</strong>

    The dataset was reduced from 8 features to only two, implying that much of the data variation (considerd by K-Means during clustering) is hidden in this planar representation.
  </figcaption>


  </figure>
</div>

<h5 id="discussions-1">Discussions</h5>

<p>We are limited by the number of attributes that can be plotted at the same time in a scatterplot. Considering the California Dataset has more than two features, not all information is shown in the chart above.
We opted to use PCA <a class="citation" href="#kurita2019principal">[6]</a> as a visualization method to select the directions of most variability in the assignment of clusters and further improve the visualization.
We remark that this step is performed <strong>after</strong> K-Means execution, and therefore does not affect the results of the clustering method.</p>

<p>From the scatterplot above, we observe this set represents a much more complex structure than the Cluster.dat Dataset.</p>

<h4 id="application-over-the-tf-flowers-dataset">Application over The TF-Flowers Dataset</h4>

<h5 id="preparing">Preparing</h5>

<p>In order to use K-Means, as implemented above, we transform our image dataset into a feature-vector dataset.
Furthermore, we “normalize” the samples features (pixels) by compressing their RGB values $[0, 256)$ into the $[-1, 1]$ interval.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">channels</span><span class="p">))</span>
  <span class="n">x</span> <span class="o">/=</span> <span class="mf">127.5</span>
  <span class="n">x</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">postprocess_output</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="n">z</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">z</span> <span class="o">*=</span> <span class="mf">127.5</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">z</span>
</code></pre></div></div>

<h5 id="training-2">Training</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">flowers_train</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">flowers_train_set</span><span class="p">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">flowers_train</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">flowers_train</span><span class="p">)</span>  <span class="c1"># (8, 150, 150, 3) -&gt; (180,000, 3)
</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">training_samples</span><span class="p">],</span>
                        <span class="n">maxval</span><span class="o">=</span><span class="n">flowers_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">flowers_train_selected</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">flowers_train</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (10,000, 3)
</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">uniform_clusters</span><span class="p">(</span>
  <span class="n">flowers_train</span><span class="p">,</span>
  <span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">colors</span>
<span class="p">))</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv10" aria-controls="cv10" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv10"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_images</span><span class="p">(</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="mf">127.5</span><span class="o">*</span><span class="p">(</span><span class="n">clusters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="n">rows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/69_0.png" alt="Initial color book." class="figure-img img-fluid rounded mx-auto d-block w0" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Initial color book.</strong>

    Colors are randomly drawn from an uniform random distribution.
  </figcaption>


  </figure>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="k">try</span><span class="p">:</span> <span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_fit</span><span class="p">(</span>
       <span class="n">flowers_train_selected</span><span class="p">,</span>
       <span class="n">clusters</span><span class="p">,</span>
       <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
       <span class="n">tol</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">tf_flowers</span><span class="p">.</span><span class="n">tol</span><span class="p">,</span>
       <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">KeyboardInterrupt</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">interrupted'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s">'done'</span><span class="p">)</span>

<span class="c1"># Constrain to valid image pixel values.
</span><span class="n">clusters</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">));</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 0
  Loss          <span class="o">=</span>     711.2058
  WCSS          <span class="o">=</span>       0.0711
  BCSS          <span class="o">=</span>      295.279
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9991
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 28   4   0   3   0  20  68   0  15 382   0   0 215   0  12   0  24   2
  10  22 187   0   0   2 198   9   1   0   2   0 397   0  98   0  58  59
  17  82   0   0 114   0   0   0 941   0   1   0  12 116   0 423   0   1
   0 118 107   0   0 237   0   0 114   4 894  30 533   1   0 290 594   0
   0   0  17  85   0   1 177  55   7  14   1   5   0   0   0   0   0  50
   0  42   0   0   9  15   7   7  26 116  12   0 123   0   1   0   0  99
  40 174 355  23   1   0 871 141 385 521   0  14  12   0  68   1  42   0
   0  38]
Step 10
  Loss          <span class="o">=</span>     260.2131
  WCSS          <span class="o">=</span>        0.026
  BCSS          <span class="o">=</span>     296.0636
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9991
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 32   6   0   1   0   6  60   0  11 308   0   0 336   0  12   0  36   1
   7  24 140   0   0   4 164   8   1   0   2   0 321   4 225   0  75  46
  21 136   0   0 114   0   0   0 338   0   1   0  11 327   0 225   0   0
   0 154 147   0   0 237   0   0 104   4 488  34 336   0   0 262 599   0
   0   0  24 116   0  10 179  59   6  19   1   7   0   0   0   0   0  80
   0 155   0   0 100   3  20   6  49 116  13   2 141   1   1   0   0 309
  41 180 738   3   1   0 812 320 414 475   0  32  28   0  87   1  43   0
   0  40]
Step 20
  Loss          <span class="o">=</span>     223.4796
  WCSS          <span class="o">=</span>       0.0223
  BCSS          <span class="o">=</span>     296.1174
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9992
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 32   6   0   1   0   7  64   0  12 217   0   0 290   0  19   0  63   1
   5  33 120   0   0  11 149   8   1   0   2   0 281   0 218   0  89 203
  19 145   0   0 131   0   0   0 284   0   2   0  10 370   0 207   0   0
   0 163 149   0   0 244   0   0 106   5 487  35 294   0   0 250 543   0
   0   0  20 116   0  31 192 108   6  24   1   8   0   0   0   0   0  81
   0 196   0   0 178   3  34   6  60 118  10   2 138   1   1   0   0 238
  42 207 655   4   1   0 796 266 405 419   0  60  55   0 156   1  44   0
   0  41]
Step 30
  Loss          <span class="o">=</span>     208.6662
  WCSS          <span class="o">=</span>       0.0209
  BCSS          <span class="o">=</span>     296.3314
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9993
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 31   8   0   1   0   7  68   0  13 182   0   0 288   0  24   0  70   0
   4  43 120   0   0  12 138   8   1   0   3   0 301   0 201   0  90 402
  18 129   0   0 180   0   0   0 178   0   2   0  10 349   0 184   0   0
   0 143 144   0   0 233   0   0 103   5 466  41 291   0   0 253 542   0
   0   0  17 110   0  56 180 129   6  26   1   9   0   0   0   0   0  89
   0 206   0   0 181   3  57   6  73 121   9   2 136   1   1   0   0 229
  42 221 616   4   1   0 781 245 401 368   0  74  67   0 162   1  44   0
   0  39]
Step 40
  Loss          <span class="o">=</span>     202.2344
  WCSS          <span class="o">=</span>       0.0202
  BCSS          <span class="o">=</span>      296.567
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9994
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 29   8   0   1   0   7  71   0  13 176   0   0 293   0  24   0  79   0
   4  56 127   0   0  23 138   9   1   0   3   0 307   0 194   0  91 519
  18 127   0   0 191   0   0   0 170   0   2   0  12 337   0 175   0   0
   0 137 136   0   0 227   0   0 104   5 449  45 284   0   0 254 537   0
   0   0  22 113   0  72 167 134   6  27   1   9   0   0   0   0   0  90
   0 214   0   0 171   3  75   6  78 121   9   2 123   1   2   0   0 225
  43 215 539   4   1   0 712 235 403 390   0  88  76   0 154   1  46   0
   0  39]
Step 50
  Loss          <span class="o">=</span>       198.52
  WCSS          <span class="o">=</span>       0.0199
  BCSS          <span class="o">=</span>     296.7816
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9993
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 29   8   0   1   0   7  76   0  14 173   0   0 288   0  25   0  84   0
   4  64 136   0   0  40 140  10   1   0   4   0 300   0 183   0  92 538
  18 127   0   0 195   0   0   0 165   0   1   0  12 327   0 169   0   0
   0 131 129   0   0 224   0   0 102   7 428  48 258   0   0 249 552   0
   0   0  29 118   0  94 165 142   6  29   1   9   0   0   0   0   0  86
   0 222   0   0 173   3  83   6  80 119   9   2 116   1   2   0   0 224
  43 218 535   5   1   0 687 224 398 395   0  96  85   0 148   1  46   0
   0  40]
Step 60
  Loss          <span class="o">=</span>     195.9817
  WCSS          <span class="o">=</span>       0.0196
  BCSS          <span class="o">=</span>     296.8312
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9993
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 28  10   0   1   0   7  84   0  14 173   0   0 292   0  26   0  80   0
   4  63 140   0   0  65 143  10   1   0   4   0 297   0 176   0  94 522
  19 133   0   0 192   0   0   0 156   0   1   0  13 307   0 167   0   0
   0 127 127   0   0 217   0   0 102   8 401  49 251   0   0 245 564   0
   0   0  46 115   0 126 164 148   6  31   1   9   0   0   0   0   0  85
   0 224   0   0 169   3  82   6  81 119  10   4 116   1   2   0   0 223
  43 218 550   5   1   0 685 219 397 387   0  96  89   0 137   1  46   0
   0  42]
Step 70
  Loss          <span class="o">=</span>     193.5877
  WCSS          <span class="o">=</span>       0.0194
  BCSS          <span class="o">=</span>      296.789
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9993
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 25  10   0   1   0   6  89   0  15 173   0   0 283   0  26   0  78   0
   6  64 134   0   0  91 142  11   1   0   4   0 288   0 170   0  95 517
  19 141   0   0 191   0   0   0 154   0   1   0  16 307   0 171   0   0
   0 137 125   0   0 215   0   0 102  10 371  50 242   0   0 239 569   0
   0   0  59 115   0 164 159 151   7  33   1  10   0   0   0   0   0  85
   0 233   0   0 161   3  80   6  82 117   9   4 111   1   2   0   0 223
  42 220 551   8   1   0 684 210 402 381   0  83  95   0 127   1  47   0
   0  43]
Step 80
  Loss          <span class="o">=</span>     191.9187
  WCSS          <span class="o">=</span>       0.0192
  BCSS          <span class="o">=</span>     296.7511
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9992
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 24  11   0   1   0   6  88   0  16 174   0   0 284   0  27   0  78   0
   9  65 136   0   0 107 142  11   1   0   4   0 279   0 166   0  93 510
  22 150   0   0 195   1   0   0 151   0   1   0  17 301   0 171   0   0
   0 140 123   0   0 219   0   0 102  10 349  54 242   0   0 235 561   0
   0   0  65 115   0 197 155 150   7  31   1  13   0   0   0   0   0  86
   0 239   0   0 169   3  78   6  81 116   9   4 108   1   2   0   0 219
  43 216 550   9   1   0 687 201 398 378   0  80  92   0 118   1  49   0
   0  46]
Step 90
  Loss          <span class="o">=</span>      190.467
  WCSS          <span class="o">=</span>        0.019
  BCSS          <span class="o">=</span>     296.7254
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9992
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 24  11   0   1   0   6  89   0  16 174   0   0 278   0  27   0  81   0
  18  64 127   0   0 124 142  11   1   0   4   0 267   0 160   0  93 510
  24 153   0   0 201   1   0   0 151   0   1   0  17 300   0 171   0   0
   0 144 123   0   0 217   0   0 102  10 342  58 242   0   0 242 558   0
   0   0  67 114   0 213 154 150   7  31   1  14   0   0   0   0   0  88
   0 231   0   0 176   3  81   6  80 115   9   5 105   1   2   0   0 215
  41 218 550  12   1   0 687 193 389 373   0  75  94   0 116   1  50   0
   0  47]
Step 100
  Loss          <span class="o">=</span>     188.9857
  WCSS          <span class="o">=</span>       0.0189
  BCSS          <span class="o">=</span>     296.6828
  Silhouette    <span class="o">=</span>      <span class="nt">-0</span>.9992
  WC Silhouette <span class="o">=</span>      <span class="nt">-0</span>.0078
  Samples       <span class="o">=</span> <span class="o">[</span> 23  11   0   1   0  10  91   0  18 177   0   0 275   0  27   0  82   0
  24  62 137   0   0 129 141  11   1   0   4   0 261   0 158   0  90 503
  25 154   0   0 198   1   0   0 148   0   1   0  17 286   0 170   0   0
   0 151 119   0   0 216   0   0 102  11 327  60 237   0   0 247 540   0
   0   0  67 111   0 239 153 150   8  39   1  15   0   0   0   0   0  89
   0 231   0   0 209   3  82   6  79 112   9   5 101   1   2   0   0 216
  40 220 545  16   1   0 687 183 384 369   0  73  96   0 113   1  51   0
   0  47]
<span class="k">done
</span>CPU <span class="nb">times</span>: user 3min 40s, sys: 27.3 s, total: 4min 7s
Wall <span class="nb">time</span>: 2min 32s
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv11" aria-controls="cv11" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv11"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_images</span><span class="p">(</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="mf">127.5</span><span class="o">*</span><span class="p">(</span><span class="n">clusters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="n">rows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/71_0.png" alt="Optimized color book" class="figure-img img-fluid rounded mx-auto d-block w0" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Optimized color book.</strong>

    Each cluster's centroid (representing a color in the color book) is optimized to better represent the original images.
  </figcaption>


  </figure>
</div>

<h5 id="transforming-images">Transforming Images</h5>

<p>Images are encoded by replacing each pixel in the images by its cluster index (three 32-bit floating numbers are replaced by an 32-bit integer),
and reconstructed by replacing the cluster index by the cluster point itself.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">flowers_test_set</span><span class="p">.</span><span class="n">take</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="c1"># Encoding:
</span>  <span class="n">y</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">clusters</span><span class="p">)</span>

  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Encoding </span><span class="si">{</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s"> images:'</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'  shape: </span><span class="si">{</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s"> to </span><span class="si">{</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'  size:  </span><span class="si">{</span><span class="n">size_in_mb</span><span class="p">(</span><span class="n">x</span><span class="p">):.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MB to </span><span class="si">{</span><span class="n">size_in_mb</span><span class="p">(</span><span class="n">y</span><span class="p">):.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MB'</span><span class="p">)</span>

  <span class="c1"># Decoding:
</span>  <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">postprocess_output</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

  <span class="n">visualize_images</span><span class="p">([</span><span class="o">*</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">uint32</span><span class="p">),</span> <span class="o">*</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">uint32</span><span class="p">)],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Encoding 8 images:
  shape: <span class="o">(</span>8, 150, 150, 3<span class="o">)</span> to <span class="o">(</span>180000,<span class="o">)</span>
  size:  4.12 MB to 1.37 MB
Encoding 8 images:
  shape: <span class="o">(</span>8, 150, 150, 3<span class="o">)</span> to <span class="o">(</span>180000,<span class="o">)</span>
  size:  4.12 MB to 1.37 MB
Encoding 8 images:
  shape: <span class="o">(</span>8, 150, 150, 3<span class="o">)</span> to <span class="o">(</span>180000,<span class="o">)</span>
  size:  4.12 MB to 1.37 MB
</code></pre></div></div>

<div id="carouselFlowersKmeans" class="carousel slide carousel-dark w-xl-auto" data-bs-ride="carousel" alt="Color quantization results over images in TF-Flowers Test Subset.">
  <div class="carousel-inner">
    <div class="carousel-item active"><img src="/assets/images/posts/ml/clustering/73_1.png" class="d-block w-100" /></div>
    <div class="carousel-item"><img src="/assets/images/posts/ml/clustering/73_2.png" class="d-block w-100" /></div>
    <div class="carousel-item"><img src="/assets/images/posts/ml/clustering/73_3.png" class="d-block w-100" /></div>
  </div>
  <button class="carousel-control-prev" type="button" data-bs-target="#carouselFlowersKmeans" data-bs-slide="prev">
    <span class="carousel-control-prev-icon" aria-hidden="true"></span>
    <span class="visually-hidden">Previous</span>
  </button>
  <button class="carousel-control-next" type="button" data-bs-target="#carouselFlowersKmeans" data-bs-slide="next">
    <span class="carousel-control-next-icon" aria-hidden="true"></span>
    <span class="visually-hidden">Next</span>
  </button>
</div>

<h5 id="discussions-2">Discussions</h5>

<p>Using this strategy, each $(150, 150, 3)$ image can be encoded into a $22500$-d vector.
Memory requirements for storing this information is reduced to 33.25% (0.52 MB to 0.17 MB), plus the color code-book (global to the entire set).</p>

<p>Considering only the 24 test samples above, details seem to have been correctly preserved in all images.
Conversely, smooth sections of the images containing gradual color shift were most impacted by the compression process.</p>

<p>Efficacy could be improved by using more images from multiple batches.</p>

<h3 id="hierarchical-clustering">Hierarchical Clustering</h3>

<p>We implemented the bottom-up strategy for Hierarchical Clustering <a class="citation" href="#murtagh2012algorithms">[7]</a>.
This algorithm relies heavily on the greedy linkage between two shortest-distant clusters.</p>

<p>In order to efficiently perform this operation, a few assumptions are made:</p>

<ul>
  <li>The distance between each pair of points in the set does not change after the algorithm starts. Hence the distance matrix is computed only once.</li>
  <li>Linkage between clusters <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> is the same as the linkage between <code class="language-plaintext highlighter-rouge">b</code> and <code class="language-plaintext highlighter-rouge">a</code>. I.e., linkage behaves as a distance function.</li>
  <li>The <code class="language-plaintext highlighter-rouge">heapq</code> module holds an efficient handling for heap/priority queues (which is true, considering our empirical results)</li>
</ul>

<p>We start by implementing the <code class="language-plaintext highlighter-rouge">ClusterQueue</code> class.
When instantiated, an object of <code class="language-plaintext highlighter-rouge">ClusterQueue</code> receives as arguments a sample-wise distance matrix, a list of clusters (usually singletons) and a linkage function.
The heap <code class="language-plaintext highlighter-rouge">ClusterQueue#pq</code> is then built using each $\binom{|C|}{2}$ pair of clusters (and their linkage).
Two methods are now available: (1) <code class="language-plaintext highlighter-rouge">pop</code>, which retrieves the two closest clusters (according to their linkage) and (2) <code class="language-plaintext highlighter-rouge">merge</code>, which takes two clusters as arguments, merge them and add them to the heap.</p>

<p>During testing, the linkage between each sample in the test set is computed to each cluster in the training set, resulting in a cluster assignment (label) for each test sample.</p>

<h4 id="algorithm-1">Algorithm</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">heapq</span>


<span class="k">class</span> <span class="nc">ClusterQueue</span><span class="p">:</span>
  <span class="s">"""Priority Queue for sets of points (clusters).

  Arguments
  ---------
  distance: np.ndarray
    distance matrix between each pair of samples in the training data

  clusters: list of list of ints
    Starting configuration of clusters.
    Generally starts with singletons [[0], [1], [2], ...]

  linkage: str
    Linkage function used when computing distance between two clusters.

  """</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distances</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">linkage</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">distances</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span> <span class="o">=</span> <span class="n">clusters</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">linkage</span> <span class="o">=</span> <span class="n">get_linkage_by_name</span><span class="p">(</span><span class="n">linkage</span><span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">build</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s">"""Builds the priority queue containing elements (dist(a, b), a, b).
    """</span>
    <span class="n">pq</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">)):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">d_ab</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linkage</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="n">a</span><span class="p">][:,</span> <span class="n">b</span><span class="p">])</span>
        <span class="n">pq</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">d_ab</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>

    <span class="n">heapq</span><span class="p">.</span><span class="n">heapify</span><span class="p">(</span><span class="n">pq</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">pq</span> <span class="o">=</span> <span class="n">pq</span>

  <span class="k">def</span> <span class="nf">pop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Invalid links (between old clusters) might exist as we merge
</span>    <span class="c1"># and create new clusters. Continue until we find a valid one.
</span>    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
      <span class="n">d</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">heapq</span><span class="p">.</span><span class="n">heappop</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pq</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span> <span class="ow">and</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">d</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span>

  <span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="c1"># Removes `a` and `b` from `clusters`, adds the distances
</span>    <span class="c1"># `d(c, o), for all o in clusters` to the priority queue.
</span>    <span class="c1"># Finally, adds a new set `c=a+b`.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

    <span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

    <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">:</span>
      <span class="n">d_co</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linkage</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="n">c</span><span class="p">][:,</span> <span class="n">o</span><span class="p">])</span>
      <span class="n">heapq</span><span class="p">.</span><span class="n">heappush</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pq</span><span class="p">,</span> <span class="p">(</span><span class="n">d_co</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">clusters</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>


<span class="k">def</span> <span class="nf">hierarchical_clustering</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'euclidean'</span><span class="p">,</span>
    <span class="n">linkage</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'average'</span><span class="p">,</span>
    <span class="n">max_e</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">min_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">report_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
  <span class="s">"""Hierarchical Clustering.

  Arguments
  ---------
  x: np.ndarray
    Training data.
  metric: str
    Passed to `scipy.spatial.distance.cdist`. Metric used when computing
    distances between each pair of samples. Options are:
      braycurtis, canberra, chebyshev, cityblock, correlation,
      cosine, dice, euclidean, hamming, jaccard, jensenshannon,
      kulsinski, mahalanobis, matching, minkowski, rogerstanimoto,
      russellrao, seuclidean, sokalmichener, sokalsneath, sqeuclidean,
      wminkowski, yule
  linkage: Callable
    Cluster linkage strategy. Options are:
      average, single, complete
  max_e: float
    Maximum linkage that is still considered as "close". Early stopping threshold.
  min_k: int
    Minimum number of clusters before stopping. Early stopping threshold.
  max_steps: int
    Maximum number of iterations allowed. early stopping threshold.
  verbosity:
    Controls the process verbosity. Options are 0, 1 or 2.
  report_every:
    Controls how frequently evaluation is performed.

  Returns
  -------
  List of set of point indices.
    A list containing the clustered points found.
    Each element of the list is a set of indices for the first axis of the training data:

    x := [[x00, x01, x02, ...],
          [x10, x11, x12, ...],
          ... ]

    hierarchical_clustering(x, ...)
      := [[0, 4, 5], [1, 2, 6], [3, 7, 10], ...]
  """</span>
  <span class="n">cq</span> <span class="o">=</span> <span class="n">ClusterQueue</span><span class="p">(</span><span class="n">distances</span><span class="o">=</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">),</span>
                    <span class="n">clusters</span><span class="o">=</span><span class="p">[[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))],</span>
                    <span class="n">linkage</span><span class="o">=</span><span class="n">linkage</span><span class="p">)</span>
  <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">cq</span><span class="p">.</span><span class="n">clusters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">d_ab</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">cq</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">%</span> <span class="n">report_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">hc_report_evaluation</span><span class="p">(</span><span class="sa">f</span><span class="s">'Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cq</span><span class="p">.</span><span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">cq</span><span class="p">.</span><span class="n">d</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">max_e</span> <span class="ow">and</span> <span class="n">d_ab</span> <span class="o">&gt;</span> <span class="n">max_e</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">Early stopping: shortest linkage &gt; max_e [</span><span class="si">{</span><span class="n">d_ab</span><span class="p">:.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> &gt; </span><span class="si">{</span><span class="n">max_e</span><span class="p">:.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">]'</span><span class="p">)</span>
      <span class="k">break</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cq</span><span class="p">.</span><span class="n">clusters</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">min_k</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">Early stopping: k &lt;= min_k [</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cq</span><span class="p">.</span><span class="n">clusters</span><span class="p">)</span><span class="si">}</span><span class="s"> &lt;= </span><span class="si">{</span><span class="n">min_k</span><span class="si">}</span><span class="s">]'</span><span class="p">)</span>
      <span class="k">break</span>
    <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="n">max_steps</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">Early stopping: steps &gt;= max_steps set [</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s"> &gt;= </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s">]'</span><span class="p">)</span>
      <span class="k">break</span>

    <span class="n">cq</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">%</span> <span class="n">report_every</span><span class="p">:</span>
    <span class="c1"># last step, if not reported yet.
</span>    <span class="n">hc_report_evaluation</span><span class="p">(</span><span class="sa">f</span><span class="s">'Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cq</span><span class="p">.</span><span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">cq</span><span class="p">.</span><span class="n">d</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">cq</span><span class="p">.</span><span class="n">clusters</span>


<span class="k">def</span> <span class="nf">hc_report_evaluation</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="n">report</span> <span class="o">=</span> <span class="n">hc_test_step</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

  <span class="k">print</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
  <span class="n">lpad</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">report</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span>
  <span class="n">rpad</span> <span class="o">=</span> <span class="mi">12</span>

  <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">report</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'  </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s">'</span><span class="p">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">lpad</span><span class="p">),</span> <span class="s">'='</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="mi">4</span><span class="p">)).</span><span class="n">rjust</span><span class="p">(</span><span class="n">rpad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">hc_test_step</span><span class="p">(</span>
    <span class="n">s</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">,</span>
    <span class="n">clusters</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'euclidean'</span><span class="p">,</span>
    <span class="n">linkage</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'average'</span><span class="p">,</span>
    <span class="n">d</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span> <span class="o">=</span> <span class="bp">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
  <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1"># Reuse distance matrix if it was already computed.
</span>    <span class="n">d</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>

  <span class="n">linkage</span> <span class="o">=</span> <span class="n">get_linkage_by_name</span><span class="p">(</span><span class="n">linkage</span><span class="p">)</span>

  <span class="c1"># Samples in the training set `x` have trivial labels.
</span>  <span class="n">yx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span> <span class="n">yx</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">ix</span>

  <span class="c1"># Calculate labels in sample set `s`.
</span>  <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">linkage</span><span class="p">(</span><span class="n">d</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">]</span>
  <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">samples</span> <span class="o">=</span> <span class="n">HCMetrics</span><span class="p">.</span><span class="n">samples_per_cluster</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
  <span class="n">wss_</span> <span class="o">=</span> <span class="n">HCMetrics</span><span class="p">.</span><span class="n">WCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">linkage</span><span class="p">)</span>
  <span class="n">bss_</span> <span class="o">=</span> <span class="n">HCMetrics</span><span class="p">.</span><span class="n">BCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">linkage</span><span class="p">)</span>
  <span class="n">sil_</span> <span class="o">=</span> <span class="n">HCMetrics</span><span class="p">.</span><span class="n">silhouette</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">linkage</span><span class="p">)</span>
  <span class="n">wc_sil_</span> <span class="o">=</span> <span class="n">HCMetrics</span><span class="p">.</span><span class="n">wc_avg_silhouette</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">linkage</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
    <span class="p">(</span><span class="s">'Loss'</span><span class="p">,</span> <span class="s">'WCSS'</span><span class="p">,</span> <span class="s">'BCSS'</span><span class="p">,</span> <span class="s">'Silhouette'</span><span class="p">,</span> <span class="s">'WC Silhouette'</span><span class="p">,</span> <span class="s">'Clusters'</span><span class="p">,</span> <span class="s">'Samples'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">wss_</span><span class="p">)),</span>
     <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">wss_</span><span class="p">)),</span>
     <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">bss_</span><span class="p">)),</span>
     <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sil_</span><span class="p">),</span>
     <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">wc_sil_</span><span class="p">),</span>
     <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">),</span>
     <span class="n">samples</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
  <span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hc_search</span><span class="p">(</span>
  <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
  <span class="n">params</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> <span class="n">ParameterGrid</span><span class="p">],</span>
  <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
  <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">:</span>
  <span class="s">"""Search for Hyper-Parameter Optimization.

  Returns
  -------
    pd.DataFrame
      The search results report.
  """</span>
  <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'params: </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

    <span class="n">clusters</span> <span class="o">=</span> <span class="n">hierarchical_clustering</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">p</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">hc_test_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">p</span><span class="p">[</span><span class="s">'metric'</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="s">'linkage'</span><span class="p">])</span>
    <span class="n">results</span> <span class="o">+=</span> <span class="p">[{</span><span class="s">'config_id'</span><span class="p">:</span> <span class="n">ix</span><span class="p">,</span> <span class="s">'params'</span><span class="p">:</span> <span class="n">p</span><span class="p">,</span> <span class="o">**</span><span class="n">metrics</span><span class="p">}]</span>

  <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hc_predict</span><span class="p">(</span>
  <span class="n">s</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
  <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
  <span class="n">clusters</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
  <span class="n">metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'euclidean'</span><span class="p">,</span>
  <span class="n">linkage</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">'average'</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">:</span>
  <span class="s">"""Hierarchical Clustering Predict.

  Predict new samples based on minimal distance to existing clusters,
  without altering their current configuration.

  """</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
  <span class="n">linkage</span> <span class="o">=</span> <span class="n">get_linkage_by_name</span><span class="p">(</span><span class="n">linkage</span><span class="p">)</span>

  <span class="c1"># We need a label for every single point, so we calculate
</span>  <span class="c1"># single point-to-cluster distance (hence axis=1).
</span>  <span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">linkage</span><span class="p">(</span><span class="n">d</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">]</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">l</span>
</code></pre></div></div>

<h4 id="linkage-and-evaluation-metrics">Linkage and Evaluation Metrics</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">single_linkage</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">average_linkage</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">complete_linkage</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_linkage_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">_linkage'</span><span class="p">]</span>


<span class="c1"># Metrics
</span>
<span class="k">class</span> <span class="nc">HCMetrics</span><span class="p">:</span>
  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">WCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">reducer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">linkage</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">yx</span> <span class="o">==</span> <span class="n">label</span><span class="p">][:,</span> <span class="n">yc</span> <span class="o">==</span> <span class="n">label</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">yx</span><span class="p">)]</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">BCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">reducer</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">linkage</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">yx</span> <span class="o">==</span> <span class="n">label</span><span class="p">][:,</span> <span class="n">yc</span> <span class="o">!=</span> <span class="n">label</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">yx</span><span class="p">)]</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">silhouette</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">HCMetrics</span><span class="p">.</span><span class="n">WCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">HCMetrics</span><span class="p">.</span><span class="n">BCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">wc_avg_silhouette</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">):</span>
    <span class="c1"># WCSS and BCSS return tensors in the shape (clusters, samples),
</span>    <span class="c1"># so we can simply zip them together:
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">([</span>
      <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">HCMetrics</span><span class="p">.</span><span class="n">WCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">),</span>
                      <span class="n">HCMetrics</span><span class="p">.</span><span class="n">BCSS</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">yx</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">linkage</span><span class="p">))</span>
    <span class="p">])</span>

  <span class="o">@</span><span class="nb">staticmethod</span>
  <span class="k">def</span> <span class="nf">samples_per_cluster</span><span class="p">(</span><span class="n">yx</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">yx</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="application-over-the-clusterdat-dataset-1">Application over The Cluster.dat Dataset</h4>

<h5 id="searching">Searching</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">hc_search</span><span class="p">(</span>
  <span class="n">cluster_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="n">params</span><span class="o">=</span><span class="n">ParameterGrid</span><span class="p">({</span>
    <span class="s">'metric'</span><span class="p">:</span> <span class="p">[</span><span class="s">'euclidean'</span><span class="p">],</span>    <span class="c1"># ... 'correlation'] --- different metrics aren't directly comparable.
</span>    <span class="s">'linkage'</span><span class="p">:</span> <span class="p">[</span><span class="s">'average'</span><span class="p">],</span>   <span class="c1"># ... 'average', 'complete'] --- different linkages aren't directly comparable.
</span>    <span class="s">'max_e'</span><span class="p">:</span> <span class="p">[.</span><span class="mi">4</span><span class="p">,</span> <span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="p">.</span><span class="mi">6</span><span class="p">,</span> <span class="p">.</span><span class="mi">7</span><span class="p">,</span> <span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="p">.</span><span class="mi">9</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
    <span class="s">'min_k'</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span>
  <span class="p">}),</span>
  <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">).</span><span class="n">set_index</span><span class="p">(</span><span class="s">'config_id'</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 0.4, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 0.5, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 0.6, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 0.7, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 0.8, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 0.9, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 1.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span>, <span class="s1">'min_k'</span>: 3<span class="o">}</span>
CPU <span class="nb">times</span>: user 37.1 s, sys: 356 ms, total: 37.5 s
Wall <span class="nb">time</span>: 37.6 s
</code></pre></div></div>

<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
  <tr>
    <th>config_id</th>
    <th>params</th>
    <th>Loss</th>
    <th>WCSS</th>
    <th>BCSS</th>
    <th>Silhouette</th>
    <th>WC Silhouette</th>
    <th>Clusters</th>
    <th>Samples</th>
  </tr></thead>
<tbody>
  <tr>
    <td>0</td>
    <td>{'linkage': 'average', 'max_e': 0.4, 'metric':...</td>
    <td>123.15</td>
    <td>0.24</td>
    <td>1.83</td>
    <td>0.87</td>
    <td>0.87</td>
    <td>22</td>
    <td>[18, 21, 19, 17, 12, 26, 26, 24, 15, 26]</td>
  </tr>
  <tr>
    <td>1</td>
    <td>{'linkage': 'average', 'max_e': 0.5, 'metric':...</td>
    <td>172.52</td>
    <td>0.33</td>
    <td>1.90</td>
    <td>0.82</td>
    <td>0.82</td>
    <td>12</td>
    <td>[23, 35, 51, 29, 32, 47, 27, 60, 59, 40]</td>
  </tr>
  <tr>
    <td>2</td>
    <td>{'linkage': 'average', 'max_e': 0.6, 'metric':...</td>
    <td>188.88</td>
    <td>0.37</td>
    <td>1.92</td>
    <td>0.80</td>
    <td>0.81</td>
    <td>10</td>
    <td>[27, 34, 47, 72, 59, 44, 69, 54, 64, 46]</td>
  </tr>
  <tr>
    <td>3</td>
    <td>{'linkage': 'average', 'max_e': 0.7, 'metric':...</td>
    <td>210.21</td>
    <td>0.41</td>
    <td>1.96</td>
    <td>0.78</td>
    <td>0.79</td>
    <td>8</td>
    <td>[35, 88, 59, 56, 54, 73, 60, 91]</td>
  </tr>
  <tr>
    <td>4</td>
    <td>{'linkage': 'average', 'max_e': 0.8, 'metric':...</td>
    <td>271.66</td>
    <td>0.53</td>
    <td>2.10</td>
    <td>0.74</td>
    <td>0.75</td>
    <td>5</td>
    <td>[48, 121, 131, 113, 103]</td>
  </tr>
  <tr>
    <td>5</td>
    <td>{'linkage': 'average', 'max_e': 0.9, 'metric':...</td>
    <td>334.00</td>
    <td>0.65</td>
    <td>2.39</td>
    <td>0.72</td>
    <td>0.73</td>
    <td>3</td>
    <td>[113, 252, 151]</td>
  </tr>
  <tr>
    <td>6</td>
    <td>{'linkage': 'average', 'max_e': 1.0, 'metric':...</td>
    <td>334.00</td>
    <td>0.65</td>
    <td>2.39</td>
    <td>0.72</td>
    <td>0.73</td>
    <td>3</td>
    <td>[113, 252, 151]</td>
  </tr>
</tbody>
</table>
</div>

<h5 id="training-3">Training</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
  <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span>
  <span class="n">linkage</span><span class="o">=</span><span class="s">'average'</span><span class="p">,</span>
  <span class="n">max_e</span><span class="o">=</span><span class="p">.</span><span class="mi">9</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">hierarchical_clustering</span><span class="p">(</span>
  <span class="n">cluster_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="o">**</span><span class="n">params</span><span class="p">,</span>
  <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">report_every</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 250
  Loss          <span class="o">=</span>      17.0699
  WCSS          <span class="o">=</span>       0.0331
  BCSS          <span class="o">=</span>       1.7615
  Silhouette    <span class="o">=</span>       0.9805
  WC Silhouette <span class="o">=</span>       0.9852
  Clusters      <span class="o">=</span>          267
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 1 1 1 1 1 1]
Step 500
  Loss          <span class="o">=</span>     143.1246
  WCSS          <span class="o">=</span>       0.2774
  BCSS          <span class="o">=</span>       1.8524
  Silhouette    <span class="o">=</span>       0.8452
  WC Silhouette <span class="o">=</span>       0.8511
  Clusters      <span class="o">=</span>           17
  Samples       <span class="o">=</span> <span class="o">[</span>16 26 30 26 35 35 28 30 35 25]

Early stopping: shortest linkage <span class="o">&gt;</span> max_e <span class="o">[</span>2.1811 <span class="o">&gt;</span> 0.9000]
Step 514
  Loss          <span class="o">=</span>     333.9982
  WCSS          <span class="o">=</span>       0.6473
  BCSS          <span class="o">=</span>       2.3875
  Silhouette    <span class="o">=</span>       0.7229
  WC Silhouette <span class="o">=</span>       0.7328
  Clusters      <span class="o">=</span>            3
  Samples       <span class="o">=</span> <span class="o">[</span>113 252 151]
CPU <span class="nb">times</span>: user 6.54 s, sys: 36.8 ms, total: 6.57 s
Wall <span class="nb">time</span>: 6.72 s
</code></pre></div></div>

<h5 id="evaluate">Evaluate</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_train</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span><span class="n">cluster_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cluster_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">clusters</span><span class="p">,</span>
                     <span class="n">params</span><span class="p">[</span><span class="s">'metric'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'linkage'</span><span class="p">])</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span><span class="n">cluster_test</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cluster_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">clusters</span><span class="p">,</span>
                    <span class="n">params</span><span class="p">[</span><span class="s">'metric'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'linkage'</span><span class="p">])</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv13" aria-controls="cv13" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv13"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">cluster_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">cluster_test</span><span class="p">,</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/91_0.png" alt="Hierarchical Clustering over Cluster.dat Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Hierarchical Clustering over Cluster.dat Dataset.</strong>

    HC found a data structure similar to the one discovered by K-Means. No centroids are produced by construction, but they can be inferred using some aggregation function over samples for each cluster, such as mean or median.
  </figcaption>


  </figure>
</div>

<h5 id="discussions-3">Discussions</h5>

<p>We assume multiple distances and linkages are not directly comparable, considering their differences in construction. For example, single linkage will always return lower values than average and complete linkage.
Therefore, we only searched within a single combination of metric and linkage.</p>

<p>For Hierarchical Clustering, WCSS is minimal when all clusters are singleton, and will increase as the algorithm progresses. BCSS also increases as samples in the set are aggregated into fewer clusters, as their centroids become increasingly more distant from each other.
Furthermore, as the within cluster linkage tends to <code class="language-plaintext highlighter-rouge">0</code>, <code class="language-plaintext highlighter-rouge">max(a, b)</code> tends to <code class="language-plaintext highlighter-rouge">b</code>, and the Silhouette tends to 1. As the algorithm executes, increasing <code class="language-plaintext highlighter-rouge">a</code>, the Avg. Silhouette decreases.</p>

<p>We were limited to search for the <code class="language-plaintext highlighter-rouge">max_e</code> and <code class="language-plaintext highlighter-rouge">min_k</code> parameters. As these are early stopping arguments and will dictate for how many iterations the algorithm will run, it becomes clear that larger <code class="language-plaintext highlighter-rouge">max_e</code>/lower <code class="language-plaintext highlighter-rouge">min_k</code> will always result in lower <code class="language-plaintext highlighter-rouge">Avg. Silhouette</code> values.
Therefore, we selected the winning searching arguments based on how many clusters they would produce, as well as the amount of samples in each cluster.</p>

<p>The Cluster.dat Dataset was once again easily clustered using $e=0.9$.
The algorithm early stopped with the min distance threshold ($min(d) = 2.1811 &gt; e=0.9$), and have correctly found the 3 clusters for the set.</p>

<h4 id="application-over-the-california-dataset-1">Application over The California Dataset</h4>

<h5 id="searching-1">Searching</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">hc_search</span><span class="p">(</span>
  <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="n">params</span><span class="o">=</span><span class="n">ParameterGrid</span><span class="p">({</span>
    <span class="s">'metric'</span><span class="p">:</span> <span class="p">[</span><span class="s">'euclidean'</span><span class="p">],</span>
    <span class="s">'linkage'</span><span class="p">:</span> <span class="p">[</span><span class="s">'average'</span><span class="p">],</span>
    <span class="s">'max_e'</span><span class="p">:</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span>
  <span class="p">}),</span>
  <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">).</span><span class="n">set_index</span><span class="p">(</span><span class="s">'config_id'</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 3.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 4.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 5.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 6.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
CPU <span class="nb">times</span>: user 17.3 s, sys: 152 ms, total: 17.4 s
Wall <span class="nb">time</span>: 17.5 s
</code></pre></div></div>

<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
  <tr>
    <th>config_id</th>
    <th>params</th>
    <th>Loss</th>
    <th>WCSS</th>
    <th>BCSS</th>
    <th>Silhouette</th>
    <th>WC Silhouette</th>
    <th>Clusters</th>
    <th>Samples</th>
  </tr></thead>
<tbody>
  <tr>
    <td>0</td>
    <td>{'linkage': 'average', 'max_e': 3.0, 'metric':...</td>
    <td>906.72</td>
    <td>2.01</td>
    <td>4.01</td>
    <td>0.48</td>
    <td>0.70</td>
    <td>26</td>
    <td>[1, 4, 1, 1, 2, 1, 1, 1, 1, 1]</td>
  </tr>
  <tr>
    <td>1</td>
    <td>{'linkage': 'average', 'max_e': 4.0, 'metric':...</td>
    <td>1255.36</td>
    <td>2.79</td>
    <td>4.54</td>
    <td>0.37</td>
    <td>0.64</td>
    <td>14</td>
    <td>[1, 1, 1, 6, 3, 1, 1, 2, 7, 20]</td>
  </tr>
  <tr>
    <td>2</td>
    <td>{'linkage': 'average', 'max_e': 5.0, 'metric':...</td>
    <td>1510.53</td>
    <td>3.36</td>
    <td>7.56</td>
    <td>0.55</td>
    <td>0.55</td>
    <td>7</td>
    <td>[1, 20, 3, 8, 6, 2, 410]</td>
  </tr>
  <tr>
    <td>3</td>
    <td>{'linkage': 'average', 'max_e': 6.0, 'metric':...</td>
    <td>1510.53</td>
    <td>3.36</td>
    <td>7.56</td>
    <td>0.55</td>
    <td>0.55</td>
    <td>7</td>
    <td>[1, 20, 3, 8, 6, 2, 410]</td>
  </tr>
</tbody></table>
</div>

<h5 id="training-4">Training</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
  <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span>
  <span class="n">linkage</span><span class="o">=</span><span class="s">'average'</span><span class="p">,</span>
  <span class="n">max_e</span><span class="o">=</span><span class="mf">5.</span>
<span class="p">)</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">hierarchical_clustering</span><span class="p">(</span>
  <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="o">**</span><span class="n">params</span><span class="p">,</span>
  <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">report_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">).</span><span class="n">set_index</span><span class="p">(</span><span class="s">"config_id"</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 100
  Loss          <span class="o">=</span>       65.996
  WCSS          <span class="o">=</span>       0.1467
  BCSS          <span class="o">=</span>        3.681
  Silhouette    <span class="o">=</span>       0.9552
  WC Silhouette <span class="o">=</span>       0.9769
  Clusters      <span class="o">=</span>          351
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 1 1 1 1 1 1]
Step 200
  Loss          <span class="o">=</span>     175.0656
  WCSS          <span class="o">=</span>        0.389
  BCSS          <span class="o">=</span>       3.6891
  Silhouette    <span class="o">=</span>       0.8829
  WC Silhouette <span class="o">=</span>       0.9413
  Clusters      <span class="o">=</span>          251
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 1 1 1 1 1 1]
Step 300
  Loss          <span class="o">=</span>     341.0692
  WCSS          <span class="o">=</span>       0.7579
  BCSS          <span class="o">=</span>       3.7056
  Silhouette    <span class="o">=</span>       0.7775
  WC Silhouette <span class="o">=</span>       0.8766
  Clusters      <span class="o">=</span>          151
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 2 1 1 1 1 1]
Step 400
  Loss          <span class="o">=</span>     704.2004
  WCSS          <span class="o">=</span>       1.5649
  BCSS          <span class="o">=</span>       3.8376
  Silhouette    <span class="o">=</span>       0.5691
  WC Silhouette <span class="o">=</span>       0.7321
  Clusters      <span class="o">=</span>           51
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 4 1 1 4 1 1 2 1]

Early stopping: shortest linkage <span class="o">&gt;</span> max_e <span class="o">[</span>6.5662 <span class="o">&gt;</span> 5.0000]
Step 444
  Loss          <span class="o">=</span>    1510.5264
  WCSS          <span class="o">=</span>       3.3567
  BCSS          <span class="o">=</span>       7.5577
  Silhouette    <span class="o">=</span>       0.5474
  WC Silhouette <span class="o">=</span>       0.5509
  Clusters      <span class="o">=</span>            7
  Samples       <span class="o">=</span> <span class="o">[</span>  1  20   3   8   6   2 410]
CPU <span class="nb">times</span>: user 4.9 s, sys: 53.2 ms, total: 4.96 s
Wall <span class="nb">time</span>: 4.95 s
</code></pre></div></div>

<h5 id="evaluate-1">Evaluate</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_train</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s">'metric'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'linkage'</span><span class="p">])</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s">'metric'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'linkage'</span><span class="p">])</span>
</code></pre></div></div>
<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv14" aria-controls="cv14" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-py collapse highlighter-rouge" id="cv14"><div class="highlight"><pre class="highlight"><code><span class="n">e</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">),</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">),</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/101_0.png" alt="Hierarchical Clustering over California Dataset." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title"></strong>

    Hierarchical Clustering over California Dataset.
  </figcaption>


  </figure>
</div>

<h5 id="discussions-4">Discussions</h5>

<p>We selected $e=5.0$, as this configuration resulted in 5 clusters more evenly balanced, with three seemly containing outliers. Greater values for $e$ resulted in a single main cluster being found, and two more containing few outlying samples.</p>

<p>The neighboring clusters found by K-Means have disapeared here. Furthermore, sparsely outlying samples have been clustered into small subsets (comprising of few samples).
This confirms the search results found when applying the K-Means algorithm, which described this set as being dominated by two large clusters ($k=2$).</p>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv15" aria-controls="cv15" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv15"><div class="highlight"><pre class="highlight"><code><span class="n">e</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">z_train</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">)</span>
<span class="n">z_test</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">)</span>

<span class="n">linkages</span> <span class="o">=</span> <span class="p">(</span><span class="s">'single'</span><span class="p">,</span> <span class="s">'average'</span><span class="p">,</span> <span class="s">'complete'</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">for</span> <span class="n">linkage</span> <span class="ow">in</span> <span class="n">linkages</span><span class="p">:</span>
  <span class="n">clusters</span> <span class="o">=</span> <span class="n">hierarchical_clustering</span><span class="p">(</span>
    <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span>
    <span class="n">linkage</span><span class="o">=</span><span class="n">linkage</span><span class="p">,</span>
    <span class="n">max_e</span><span class="o">=</span><span class="mf">4.</span><span class="p">,</span>
    <span class="n">min_k</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">p_train</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span>
    <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">clusters</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span>
    <span class="n">linkage</span><span class="o">=</span><span class="n">linkage</span><span class="p">)</span>
  <span class="n">p_test</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span>
    <span class="n">cali_x_test</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">cali_x_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">clusters</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span>
    <span class="n">linkage</span><span class="o">=</span><span class="n">linkage</span><span class="p">)</span>

  <span class="n">results</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">p_train</span><span class="p">,</span> <span class="n">p_test</span><span class="p">)]</span>


<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="p">(</span><span class="n">linkage</span><span class="p">,</span> <span class="p">(</span><span class="n">p_train</span><span class="p">,</span> <span class="n">p_test</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">linkages</span><span class="p">,</span> <span class="n">results</span><span class="p">)):</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">ix</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">visualize_clusters</span><span class="p">(</span>
    <span class="p">(</span><span class="n">z_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
    <span class="p">(</span><span class="n">z_test</span><span class="p">,</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s">'Hierarchical Clustering of California</span><span class="se">\n</span><span class="s">Euclidean </span><span class="si">{</span><span class="n">linkage</span><span class="si">}</span><span class="s"> Linkage'</span><span class="p">,</span>
    <span class="n">full</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="bp">False</span>
  <span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<div style="" class="w-lg-100 w-xl-175 text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/103_0.png" alt="Effect of the different linkages over the clustering's final configuration." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Effect of the different linkages over the clustering's final configuration.</strong>

    
  </figcaption>


  </figure>
</div>

<p>Single linkage is capable of finding non-linear relationships, where clusters are associated by their closest link, so non-spherical shaped clusters might appear (such as the pink one in the first plot). A downside of this linkage is the possible construction of unbalance clusters when data density varies across the space.
This behavior can be observed in the California Dataset, were samples in the left-center are closely positioned, in opposite of the few samples on the right-bottom.</p>

<p>Complete linkage favors concise clusters in opposite of large ones, in which all samples are closely related. We observed for this example that the large data mass in the left-center was subdivided into multiple different clusters.</p>

<p>Average linkage seems as a compromise between Single and Complete linkage, pondering between cluster central similarity and sample conciseness.</p>

<h2 id="part-2-dimensionality-reduction">Part-2: Dimensionality Reduction</h2>

<p><strong>How/if normalization affected our results</strong></p>

<p>For a dataset $X$, where each feature is centered in $0$, Principal Component Analysis (PCA) can be expressed as the Singular Value Decomposition of the covariance matrix $XX^\intercal$ (which has the same sigular components as the matrix $X$).
In a set of many features within different intervals, some features present larger variance intervals than others.
In such cases, the sigular components will focus on modeling these directions, as their composition represent the highest total variance of the set.
While this is interesting in many analytical cases, it is usually an unwanted behavior in Machine Learning: features should be favored based on how well they explain the overall data, independently of their natural variance.</p>

<p>A second formulation of the PCA can then be defined over the correlation matrix $\frac{XX^\intercal}{\sigma(X)^2}$. In this form, all features will vary in the same interval ($\mu_X=0, \sigma =1$), and the singular components will exclusively model the relationship between the variables.
An easy way to achieve this form is to simply standardize the data (dividing each column by its standard deviation) before applying PCA. The new set will have $\sigma(X’)=1$ and its covariance and correlation matrices will be the same. The two scatterplots below show the difference between the two formulations on the California Dataset.</p>

<p>For the purposes of this assignment, all our PCA runs are based on the decomposition of the correlation matrix.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">e</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">b_cov_train</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">inverse_standardize</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">,</span> <span class="n">b_u</span><span class="p">,</span> <span class="n">b_s</span><span class="p">))</span>
<span class="n">b_cov_test</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">inverse_standardize</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">,</span> <span class="n">b_u</span><span class="p">,</span> <span class="n">b_s</span><span class="p">))</span>

<span class="n">b_cor_train</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">)</span>
<span class="n">b_cor_test</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv16" aria-controls="cv16" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv16"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'PCA over The Covariance Matrix'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">b_cov_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">b_cov_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">b_cov_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">b_cov_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'PCA over The Correlation Matrix'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">b_cor_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">b_cor_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">b_cor_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">b_cor_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">cali_y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>


<span class="k">del</span> <span class="n">e</span><span class="p">,</span> <span class="n">b_cov_train</span><span class="p">,</span> <span class="n">b_cov_test</span><span class="p">,</span> <span class="n">b_cor_train</span><span class="p">,</span> <span class="n">b_cor_test</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/107_0.png" alt="Effect of data standardization over Eigen Decomposition." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title"></strong>

    Effect of data standardization over Eigen Decomposition.
  </figcaption>


  </figure>
</div>

<h3 id="k-means-1">K-Means</h3>
<h4 id="application-over-the-california-dataset-2">Application over The California Dataset</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">energies</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="p">.</span><span class="mi">85</span><span class="p">,</span> <span class="p">.</span><span class="mi">9</span><span class="p">,</span> <span class="p">.</span><span class="mi">95</span><span class="p">,</span> <span class="p">.</span><span class="mi">99</span><span class="p">]</span>
<span class="n">reductions</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Data dimensionality: </span><span class="si">{</span><span class="n">cali_x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">energy</span> <span class="ow">in</span> <span class="n">energies</span><span class="p">:</span>
  <span class="n">e</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">energy</span><span class="p">)</span>
  <span class="n">tr</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cali_x_train</span><span class="p">)</span>
  <span class="n">te</span> <span class="o">=</span> <span class="n">e</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cali_x_test</span><span class="p">)</span>

  <span class="n">tr</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">te</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">te</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="n">reductions</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">tr</span><span class="p">,</span> <span class="n">te</span><span class="p">))</span>

  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Components used to explain e=</span><span class="si">{</span><span class="n">energy</span><span class="p">:.</span><span class="mi">0</span><span class="o">%</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">e</span><span class="p">.</span><span class="n">n_components_</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Data dimensionality: 8
Components used to explain <span class="nv">e</span><span class="o">=</span>50.0%: 3
Components used to explain <span class="nv">e</span><span class="o">=</span>85.0%: 5
Components used to explain <span class="nv">e</span><span class="o">=</span>90.0%: 6
Components used to explain <span class="nv">e</span><span class="o">=</span>95.0%: 6
Components used to explain <span class="nv">e</span><span class="o">=</span>99.0%: 8
</code></pre></div></div>

<h5 id="searching-k-2">Searching K</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span>
  <span class="n">kmeans_search</span><span class="p">(</span>
    <span class="n">b</span><span class="p">,</span>
    <span class="n">k_max</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">k_max</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
    <span class="n">repeats</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">repeats</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
  <span class="p">).</span><span class="n">assign</span><span class="p">(</span><span class="n">energy</span><span class="o">=</span><span class="n">e</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">energies</span><span class="p">,</span> <span class="n">reductions</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CPU <span class="nb">times</span>: user 56min 28s, sys: 7.96 s, total: 56min 36s
Wall <span class="nb">time</span>: 54min 32s
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">report</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">"Samples"</span><span class="p">]).</span><span class="n">groupby</span><span class="p">(</span><span class="s">"energy"</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
  <tr>
    <th>energy</th>
    <th>k</th>
    <th>repetition</th>
    <th>Loss</th>
    <th>WCSS</th>
    <th>BCSS</th>
    <th>Silhouette</th>
    <th>WC Silhouette</th>
  </tr></thead>
<tbody>
  <tr>
    <td>0.50</td>
    <td>6.0</td>
    <td>49.5</td>
    <td>861.71</td>
    <td>1.91</td>
    <td>66.66</td>
    <td>0.46</td>
    <td>0.10</td>
  </tr>
  <tr>
    <td>0.85</td>
    <td>6.0</td>
    <td>49.5</td>
    <td>1653.47</td>
    <td>3.67</td>
    <td>98.63</td>
    <td>0.39</td>
    <td>0.08</td>
  </tr>
  <tr>
    <td>0.90</td>
    <td>6.0</td>
    <td>49.5</td>
    <td>1909.01</td>
    <td>4.24</td>
    <td>119.18</td>
    <td>0.38</td>
    <td>0.08</td>
  </tr>
  <tr>
    <td>0.95</td>
    <td>6.0</td>
    <td>49.5</td>
    <td>1904.47</td>
    <td>4.23</td>
    <td>115.52</td>
    <td>0.37</td>
    <td>0.08</td>
  </tr>
  <tr>
    <td>0.99</td>
    <td>6.0</td>
    <td>49.5</td>
    <td>2012.37</td>
    <td>4.47</td>
    <td>116.58</td>
    <td>0.36</td>
    <td>0.08</td>
  </tr>
</tbody></table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">report</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">"Samples"</span><span class="p">]).</span><span class="n">groupby</span><span class="p">(</span><span class="s">"k"</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
<tr>
  <th>k</th><th>repetition</th><th>Loss</th><th>WCSS</th><th>BCSS</th><th>Silhouette</th><th>WC Silhouette</th><th>energy</th></tr>
</thead>
<tbody>
  <tr><td>2</td><td>49.5</td><td>2615.54</td><td>5.81</td><td>17.99</td><td>0.41</td><td>0.20</td><td>0.84</td></tr>
  <tr><td>3</td><td>49.5</td><td>2160.30</td><td>4.80</td><td>37.49</td><td>0.39</td><td>0.13</td><td>0.84</td></tr>
  <tr><td>4</td><td>49.5</td><td>1894.68</td><td>4.21</td><td>59.21</td><td>0.40</td><td>0.10</td><td>0.84</td></tr>
  <tr><td>5</td><td>49.5</td><td>1689.65</td><td>3.75</td><td>76.27</td><td>0.40</td><td>0.08</td><td>0.84</td></tr>
  <tr><td>6</td><td>49.5</td><td>1533.28</td><td>3.41</td><td>102.30</td><td>0.40</td><td>0.07</td><td>0.84</td></tr>
  <tr><td>7</td><td>49.5</td><td>1411.22</td><td>3.14</td><td>125.36</td><td>0.40</td><td>0.06</td><td>0.84</td></tr>
  <tr><td>8</td><td>49.5</td><td>1310.20</td><td>2.91</td><td>147.95</td><td>0.39</td><td>0.05</td><td>0.84</td></tr>
  <tr><td>9</td><td>49.5</td><td>1233.60</td><td>2.74</td><td>171.87</td><td>0.37</td><td>0.04</td><td>0.84</td></tr>
  <tr><td>10</td><td>49.5</td><td>1165.39</td><td>2.59</td><td>191.39</td><td>0.36</td><td>0.04</td><td>0.84</td></tr>
</tbody>
</table>
</div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv17" aria-controls="cv17" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv17"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Within-Cluster Avg Squared Error'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'WCSS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Between-Cluster Sum Squared Error'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'BCSS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Avg Silhouette'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Silhouette'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">).</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Within-Cluster Avg Silhouette'</span><span class="p">);</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">report</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'WC Silhouette'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">();</span>
</code></pre></div></div>

<div style="" class="w-lg-100 w-xl-175 text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/116_0.png" alt="Clustering metrics for each choice of number of clusters k, considering the California dataset reduced with PCA." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Clustering metrics for each choice of number of clusters k, considering the California dataset reduced with PCA.</strong>

    Results are quite similar to the ones obtained without dimensionality reduction.
  </figcaption>


  </figure>
</div>

<h5 id="training-5">Training</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_e</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># report.drop(columns=["Samples"]).groupby('energy').mean().Silhouette.argmax()
</span><span class="n">best_k</span> <span class="o">=</span> <span class="mi">6</span>   <span class="c1"># report.drop(columns=["Samples"]).groupby('k').mean().Silhouette.idxmax()
</span>
<span class="n">cali_z_train</span><span class="p">,</span> <span class="n">cali_z_test</span> <span class="o">=</span> <span class="n">reductions</span><span class="p">[</span><span class="n">best_e</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Manually selected energy: </span><span class="si">{</span><span class="n">energies</span><span class="p">[</span><span class="n">best_e</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Manually selected K (low WCSS, high Silhouette) found: </span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Manually selected energy: 0.99
  Manually selected K <span class="o">(</span>low WCSS, high Silhouette<span class="o">)</span> found: 6
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">normal_clusters</span><span class="p">(</span><span class="n">cali_z_train</span><span class="p">,</span> <span class="n">best_k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s">'ck</span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_fit</span><span class="p">(</span>
  <span class="n">cali_z_train</span><span class="p">,</span>
  <span class="n">clusters</span><span class="p">,</span>
  <span class="n">steps</span><span class="o">=</span><span class="n">Config</span><span class="p">.</span><span class="n">cali</span><span class="p">.</span><span class="n">steps</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
  <span class="n">report_every</span><span class="o">=</span><span class="mi">25</span>
<span class="p">)</span>
</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 0
  Loss          <span class="o">=</span>    3494.9949
  WCSS          <span class="o">=</span>       7.7667
  BCSS          <span class="o">=</span>      80.9852
  Silhouette    <span class="o">=</span>       0.0958
  WC Silhouette <span class="o">=</span>        0.016
  Samples       <span class="o">=</span> <span class="o">[</span> 90  57  64 127  56  56]
Step 25
  Loss          <span class="o">=</span>     1953.066
  WCSS          <span class="o">=</span>       4.3401
  BCSS          <span class="o">=</span>      65.7997
  Silhouette    <span class="o">=</span>       0.3047
  WC Silhouette <span class="o">=</span>       0.0508
  Samples       <span class="o">=</span> <span class="o">[</span> 71  39 116  75  40 109]
Step 50
  Loss          <span class="o">=</span>    1878.9374
  WCSS          <span class="o">=</span>       4.1754
  BCSS          <span class="o">=</span>      69.2139
  Silhouette    <span class="o">=</span>       0.3607
  WC Silhouette <span class="o">=</span>       0.0601
  Samples       <span class="o">=</span> <span class="o">[</span> 57  38 130  70  33 122]
Step 75
  Loss          <span class="o">=</span>    1855.3518
  WCSS          <span class="o">=</span>        4.123
  BCSS          <span class="o">=</span>       70.997
  Silhouette    <span class="o">=</span>       0.3722
  WC Silhouette <span class="o">=</span>        0.062
  Samples       <span class="o">=</span> <span class="o">[</span> 55  37 133  69  33 123]
Step 100
  Loss          <span class="o">=</span>     1850.539
  WCSS          <span class="o">=</span>       4.1123
  BCSS          <span class="o">=</span>      71.4978
  Silhouette    <span class="o">=</span>       0.3718
  WC Silhouette <span class="o">=</span>        0.062
  Samples       <span class="o">=</span> <span class="o">[</span> 53  37 134  69  34 123]
</code></pre></div></div>

<h5 id="evaluation-2">Evaluation</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_train</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cali_z_train</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">kmeans_predict</span><span class="p">(</span><span class="n">cali_z_test</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_clusters</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="n">best_k</span><span class="p">)</span>  <span class="c1"># clusters tags are trivial: [0, 1, 2, ...]
</span>
<span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Train'</span><span class="p">,</span> <span class="n">cali_z_train</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">kmeans_report_evaluation</span><span class="p">(</span><span class="s">'Test'</span><span class="p">,</span> <span class="n">cali_z_test</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train
  Loss          <span class="o">=</span>     1850.539
  WCSS          <span class="o">=</span>       4.1123
  BCSS          <span class="o">=</span>      71.4978
  Silhouette    <span class="o">=</span>       0.3718
  WC Silhouette <span class="o">=</span>        0.062
  Samples       <span class="o">=</span> <span class="o">[</span> 53  37 134  69  34 123]
Test
  Loss          <span class="o">=</span>     197.7103
  WCSS          <span class="o">=</span>       3.9542
  BCSS          <span class="o">=</span>      68.9431
  Silhouette    <span class="o">=</span>       0.3923
  WC Silhouette <span class="o">=</span>       0.0654
  Samples       <span class="o">=</span> <span class="o">[</span> 7  3 15  7  5 13]
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv18" aria-controls="cv18" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv18"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">cali_z_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">cali_z_test</span><span class="p">,</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">p_clusters</span><span class="p">,</span> <span class="s">'clusters'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/122_0.png" alt="K-Means clustering over the California dataset after dimensionalty reduction was performed." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">K-Means clustering over the California dataset after dimensionalty reduction was performed.</strong>

    
  </figcaption>


  </figure>
</div>

<h5 id="discussions-5">Discussions</h5>
<p>We do not see the curse of dimensionality in this set. In fact, as this set has been highly curated, all of its columns represent complementary information and it is impossible to reduce dimensionality without loosing some residual information.
Notwithstanding, we have found that dimensionality reduction is still helpful in this case for removing noise and normalizing correlated (oval) data masses.</p>

<p>As PCA removes the least varying components (noise) from the data, samples become naturally closer from each other, reducing Within-Cluster distances. This can be observed in the search process, where the Silhouette curve increases as we reduce the energy retained by PCA.
However, this is an artificial improvement: samples which contained different measurements in the original space are being crunched together in the reduced one, in opposite of handling the curse of dimensionality.</p>

<h3 id="hierarchical-clustering-1">Hierarchical Clustering</h3>

<h4 id="application-over-the-california-dataset-3">Application over The California Dataset</h4>

<h5 id="searching-2">Searching</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">hc_search</span><span class="p">(</span>
  <span class="n">cali_z_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="n">params</span><span class="o">=</span><span class="n">ParameterGrid</span><span class="p">({</span>
    <span class="s">'metric'</span><span class="p">:</span> <span class="p">[</span><span class="s">'euclidean'</span><span class="p">],</span>
    <span class="s">'linkage'</span><span class="p">:</span> <span class="p">[</span><span class="s">'average'</span><span class="p">],</span>
    <span class="s">'max_e'</span><span class="p">:</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span>
  <span class="p">}),</span>
  <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">).</span><span class="n">set_index</span><span class="p">(</span><span class="s">'config_id'</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 3.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 4.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 5.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
params: <span class="o">{</span><span class="s1">'linkage'</span>: <span class="s1">'average'</span>, <span class="s1">'max_e'</span>: 6.0, <span class="s1">'metric'</span>: <span class="s1">'euclidean'</span><span class="o">}</span>
CPU <span class="nb">times</span>: user 19.9 s, sys: 260 ms, total: 20.1 s
Wall <span class="nb">time</span>: 25.8 s
</code></pre></div></div>

<div class="table-responsive"><table class="dataframe table table-hover">
<thead>
  <tr><th>config_id</th><th>params</th><th>Loss</th><th>WCSS</th><th>BCSS</th><th>Silhouette</th><th>WC Silhouette</th><th>Clusters</th><th>Samples</th></tr>
</thead>
<tbody>
  <tr><td>0</td><td>{'linkage': 'average', 'max_e': 3.0, 'metric':...</td><td>906.72</td><td>2.01</td><td>4.01</td><td>0.48</td><td>0.70</td><td>26</td><td>[1, 4, 1, 1, 2, 1, 1, 1, 1, 1]</td></tr>
  <tr><td>1</td><td>{'linkage': 'average', 'max_e': 4.0, 'metric':...</td><td>1255.36</td><td>2.79</td><td>4.54</td><td>0.37</td><td>0.64</td><td>14</td><td>[1, 1, 1, 6, 3, 1, 1, 2, 7, 20]</td></tr>
  <tr><td>2</td><td>{'linkage': 'average', 'max_e': 5.0, 'metric':...</td><td>1510.53</td><td>3.36</td><td>7.56</td><td>0.55</td><td>0.55</td><td>7</td><td>[1, 20, 3, 8, 6, 2, 410]</td></tr>
  <tr><td>3</td><td>{'linkage': 'average', 'max_e': 6.0, 'metric':...</td><td>1510.53</td><td>3.36</td><td>7.56</td><td>0.55</td><td>0.55</td><td>7</td><td>[1, 20, 3, 8, 6, 2, 410]</td></tr>
</tbody>
</table>
</div>

<h5 id="training-6">Training</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">hierarchical_clustering</span><span class="p">(</span>
  <span class="n">cali_z_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">,</span>
  <span class="n">linkage</span><span class="o">=</span><span class="s">'average'</span><span class="p">,</span>
  <span class="n">max_e</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span>
  <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">report_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 100
  Loss          <span class="o">=</span>       65.996
  WCSS          <span class="o">=</span>       0.1467
  BCSS          <span class="o">=</span>        3.681
  Silhouette    <span class="o">=</span>       0.9552
  WC Silhouette <span class="o">=</span>       0.9769
  Clusters      <span class="o">=</span>          351
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 1 1 1 1 1 1]
Step 200
  Loss          <span class="o">=</span>     175.0656
  WCSS          <span class="o">=</span>        0.389
  BCSS          <span class="o">=</span>       3.6891
  Silhouette    <span class="o">=</span>       0.8829
  WC Silhouette <span class="o">=</span>       0.9413
  Clusters      <span class="o">=</span>          251
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 1 1 1 1 1 1]
Step 300
  Loss          <span class="o">=</span>     341.0692
  WCSS          <span class="o">=</span>       0.7579
  BCSS          <span class="o">=</span>       3.7056
  Silhouette    <span class="o">=</span>       0.7775
  WC Silhouette <span class="o">=</span>       0.8766
  Clusters      <span class="o">=</span>          151
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 1 2 1 1 1 1 1]
Step 400
  Loss          <span class="o">=</span>     704.2004
  WCSS          <span class="o">=</span>       1.5649
  BCSS          <span class="o">=</span>       3.8376
  Silhouette    <span class="o">=</span>       0.5691
  WC Silhouette <span class="o">=</span>       0.7321
  Clusters      <span class="o">=</span>           51
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 4 1 1 4 1 1 2 1]

Early stopping: shortest linkage <span class="o">&gt;</span> max_e <span class="o">[</span>3.5131 <span class="o">&gt;</span> 3.5000]
Step 434
  Loss          <span class="o">=</span>    1022.5621
  WCSS          <span class="o">=</span>       2.2724
  BCSS          <span class="o">=</span>       4.1128
  Silhouette    <span class="o">=</span>       0.4294
  WC Silhouette <span class="o">=</span>       0.6866
  Clusters      <span class="o">=</span>           17
  Samples       <span class="o">=</span> <span class="o">[</span>1 1 1 2 3 1 1 1 2 7]
CPU <span class="nb">times</span>: user 6.24 s, sys: 97.5 ms, total: 6.34 s
Wall <span class="nb">time</span>: 11.7 s
</code></pre></div></div>

<h5 id="evaluating">Evaluating</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_train</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span>
  <span class="n">cali_z_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="n">cali_z_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">clusters</span><span class="p">)</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">hc_predict</span><span class="p">(</span>
  <span class="n">cali_z_test</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span>
  <span class="n">cali_z_train</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">clusters</span><span class="p">)</span>
</code></pre></div></div>

<div class="text-center mb-1" style="height:1.25rem">
  <hr class="thin mb-0 border-1 sr-none " />
  <button data-bs-target="#cv19" aria-controls="cv19" class="btn rounded-5 btn-light" style="position: relative; margin-top: -2rem;" type="button" data-bs-toggle="collapse" aria-expanded="false">show collapsed</button>
</div>

<div class="language-python collapse highlighter-rouge" id="cv19"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_clusters</span><span class="p">(</span>
  <span class="p">(</span><span class="n">cali_z_train</span><span class="p">,</span> <span class="n">p_train</span><span class="p">,</span> <span class="s">'train'</span><span class="p">,</span> <span class="s">'.'</span><span class="p">),</span>
  <span class="p">(</span><span class="n">cali_z_test</span><span class="p">,</span> <span class="n">p_test</span><span class="p">,</span> <span class="s">'test'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">),</span>
  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div style="" class="text-center">
  <figure class="figure ">
    <img src="/assets/images/posts/ml/clustering/133_0.png" alt="Hierarchical clustering over the California dataset after dimensionality reduction was performed." class="figure-img img-fluid rounded mx-auto d-block w-100" />

    
  <figcaption class="figure-caption text-start">
    <strong class="title">Hierarchical clustering over the California dataset after dimensionality reduction was performed.</strong>

    
  </figcaption>


  </figure>
</div>

<h5 id="discussions-6">Discussions</h5>

<p>We re-use the 99% energy reduction previously performed and select $e=5.0$, as higher values would create a massive central cluster and only two residual ones.</p>

<p>The results obtained here were very similar to the ones without the use of PCA. Once again, we observe clusters <strong>0</strong> and <strong>1</strong> containing a few sparsely positioned samples, while cluster <strong>2</strong> and <strong>3</strong> contain most samples of the set. Cluster <strong>4</strong> is positioned on the top-middle of the space, between <strong>2</strong> and <strong>3</strong>, and contains fewer samples than both.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="kriegel2017">H.-P. Kriegel, E. Schubert, and A. Zimek, “The (black) art of runtime evaluation: Are we comparing algorithms or implementations?,” <i>Knowledge and Information Systems</i>, vol. 52, no. 2, pp. 341–378, Aug. 2017,Available at: https://doi.org/10.1007/s10115-016-1004-2</span></li>
<li><span id="arthur2006k">D. Arthur and S. Vassilvitskii, “k-means++: The advantages of careful seeding,” Stanford, 2006.</span></li>
<li><span id="kurita2019principal">T. Kurita, “Principal component analysis (PCA),” <i>Computer vision: a reference guide</i>, pp. 1–4, 2019.</span></li>
<li><span id="murtagh2012algorithms">F. Murtagh and P. Contreras, “Algorithms for hierarchical clustering: an overview,” <i>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</i>, vol. 2, no. 1, pp. 86–97, 2012.</span></li>
<li><span id="pedregosa2011">F. Pedregosa <i>et al.</i>, “Scikit-learn: Machine Learning in Python,” <i>Journal of Machine Learning Research</i>, vol. 12, pp. 2825–2830, 2011.</span></li>
<li><span id="pace1997sparse">R. K. Pace and R. Barry, “Sparse spatial autoregressions,” <i>Statistics &amp; Probability Letters</i>, vol. 33, no. 3, pp. 291–297, 1997.</span></li>
<li><span id="wiki:K-means_clustering">Wikipedia, “K-means clustering — Wikipedia, The Free Encyclopedia.” https://en.wikipedia.org/wiki/K-means_clustering, 2021.</span></li></ol>

        </div>
      </article>

      
      <div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://lucasdavid-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

      
    </div>
  </div>
</div>
<div class="empty-v-space d-none d-xl-block" style="margin-bottom: 10vh"></div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
  integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"
  integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
  integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
  onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true},{left: '\\[', right: '\\]', display: true}, {left: '$', right: '$', display: false},{left: '\\(', right: '\\)', display: false}]});"></script>

<script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script>
<script>
  anchors.options = { icon: '#' };
  anchors.add();
</script>


  <!-- <svg id="visual" viewBox="0 0 1980 300"  class="curve-container__curve curve-three" xmlns="http://www.w3.org/2000/svg"
  xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1">
  <path
    d="M0 69L55 90.2C110 111.3 220 153.7 330 169.8C440 186 550 176 660 165.5C770 155 880 144 990 139.2C1100 134.3 1210 135.7 1320 137.7C1430 139.7 1540 142.3 1650 155.5C1760 168.7 1870 192.3 1925 204.2L1980 216L1980 301L1925 301C1870 301 1760 301 1650 301C1540 301 1430 301 1320 301C1210 301 1100 301 990 301C880 301 770 301 660 301C550 301 440 301 330 301C220 301 110 301 55 301L0 301Z"
    fill="#d3d3d3"></path>
  <path
    d="M0 89L55 107.8C110 126.7 220 164.3 330 191.3C440 218.3 550 234.7 660 243.8C770 253 880 255 990 252.3C1100 249.7 1210 242.3 1320 228.8C1430 215.3 1540 195.7 1650 174.5C1760 153.3 1870 130.7 1925 119.3L1980 108L1980 301L1925 301C1870 301 1760 301 1650 301C1540 301 1430 301 1320 301C1210 301 1100 301 990 301C880 301 770 301 660 301C550 301 440 301 330 301C220 301 110 301 55 301L0 301Z"
    fill="#6a6a6a"></path>
  <path
    d="M0 229L55 232.3C110 235.7 220 242.3 330 244.3C440 246.3 550 243.7 660 247.3C770 251 880 261 990 254.8C1100 248.7 1210 226.3 1320 223.5C1430 220.7 1540 237.3 1650 233.8C1760 230.3 1870 206.7 1925 194.8L1980 183L1980 301L1925 301C1870 301 1760 301 1650 301C1540 301 1430 301 1320 301C1210 301 1100 301 990 301C880 301 770 301 660 301C550 301 440 301 330 301C220 301 110 301 55 301L0 301Z"
    fill="#121212"></path>
</svg> -->
<footer class="page-footer text-bg-dark bg-black-subtle d-print-none">
  <div class="container">
    <div class="mt-4 mb-5">
      
        <div class="row g-1 mb-4">
          
          <div class="col">
            <div class="card bg-black-subtle border-0 border-start border-dark rounded-0">
              <div class="card-body font-small pt-0 pb-0">
                <h6 class="card-title fw-bold text-light">Keras Explainable</h6>
                <p class="card-text text-light">
                  Clean implementations for AI explaining methods in Keras.
<a href="https://github.com/lucasdavid/keras-explainable" target="_new">Code</a> and
<a href="https://lucasdavid.github.io/keras-explainable" target="_new">docs</a> are available.
                </p>
              </div>
            </div>
          </div>
          
          <div class="col">
            <div class="card bg-black-subtle border-0 border-start border-dark rounded-0">
              <div class="card-body font-small pt-0 pb-0">
                <h6 class="card-title fw-bold text-light">Supporting Study Material</h6>
                <p class="card-text text-light">
                  If you are an undergrad student and are looking for additional study material,
check out our collaborative project <a href="http://comp-ufscar.github.io/">comp-ufscar.github.io</a>.
                </p>
              </div>
            </div>
          </div>
          
          <div class="col">
            <div class="card bg-black-subtle border-0 border-start border-dark rounded-0">
              <div class="card-body font-small pt-0 pb-0">
                <h6 class="card-title fw-bold text-light">Algorithms in TensorFlow</h6>
                <p class="card-text text-light">
                  I'm implementing all algorithms I find interesting using TensorFlow.
You can check it out at <a href="https://github.com/lucasdavid/algorithms-in-tensorflow/">github.com/lucasdavid/algorithms-in-tensorflow</a>.
                </p>
              </div>
            </div>
          </div>
          
          <div class="col">
            <div class="card bg-black-subtle border-0 border-start border-dark rounded-0">
              <div class="card-body font-small pt-0 pb-0">
                <h6 class="card-title fw-bold text-light">TF-Experiment</h6>
                <p class="card-text text-light">
                  And environment to run Machine Learning experiments based on components and mixins. Available at <a href="https://github.com/lucasdavid/tf-experiment">github.com/lucasdavid/tf-experiment</a>.
                </p>
              </div>
            </div>
          </div>
          
          <div class="col">
            <div class="card bg-black-subtle border-0 border-start border-dark rounded-0">
              <div class="card-body font-small pt-0 pb-0">
                <h6 class="card-title fw-bold text-light">Mineração de Dados Complexos</h6>
                <p class="card-text text-light">
                  Information around the extension program "Mineração de Dados Complexos (in Portuguese)" is available at
<a href="https://www.ic.unicamp.br/~mdc/" target="_blank">ic.unicamp.br/~mdc/</a>.
                </p>
              </div>
            </div>
          </div>
          
        </div>
        
    </div>

    <div class="text-end mt-4">
      


<div class="fs-2">
  
    <a href="https://github.com/lucasdavid"
      target="_blank"
      ><i
      aria-label="GitHub"
      class="bi bi-github link-light"></i></a>
  
  
    <a href="https://www.linkedin.com/in/ld7"
      target="_blank"
      title="LinkedIn"><i class="bi bi-linkedin text-primary sr-none"></i></a>
  
  <span itemscope itemtype="https://schema.org/Person">
    <a itemprop="sameAs" content="https://orcid.org/0000-0002-8793-7300" href="https://orcid.org/0000-0002-8793-7300"
       target="orcid.widget"
       rel="me noopener noreferrer"
       title="ORCID"
      ><img src="/assets/images/infra/32px-ORCID_iD.webp" alt="ORCID logo" class="sr-none" style="margin-bottom: 7px; width: 32px;"></a>
  </span>
  
  <a href="http://stackoverflow.com/users/2429640/lucasdavid"
     target="_blank"
     title="Stackoverflow"><i class="bi bi-code-slash link-light sr-none"></i></a>
  
    <a href="https://youtube.com/channel/UC7IWeKUy4OSlC5ripcQGD6Q"
      target="_blank"
      title="Youtube"><i class="bi bi-youtube text-danger sr-none"></i></a>
  
    <a href="mailto:mb37410l3@mozmail.com"
      target="_blank"
      title="Mail"><i class="bi bi-envelope-fill link-light sr-none"></i></a>
  
  <a href="assets/docs/lucas-david-resume.pdf"
     target="_blank"
     title="Resume"><i class="bi bi-person-lines-fill link-light sr-none"></i></a>
</div>

    </div>
    <div class="text-end">
      <p>
        ® Lucas David. Todos os direitos reservados.
      </p>
    </div>
</div>
</footer>

  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js"
    integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r"
    crossorigin="anonymous" defer></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js"
    integrity="sha384-0pUGZvbkm6XF6gxjEnlmuGrJXVbNuzT9qBBavbLwCsOGabYfZo0T0to5eqruptLy"
    crossorigin="anonymous" defer></script>

</body>
</html>
