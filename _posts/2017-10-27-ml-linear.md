---
layout: post
title: Introdução ao aprendizado de máquina, pt. 2
excerpt: Um guia compreensível, em Português e Python.
date: 2017-10-26 21:43:00
---

# Modelos lineares

Um guia compreensível, em Português e Python.

Aqui, vamos falar um pouco sobre modelos lineares e seus funcionamentos básicos.
Exemplos são dados por trechos de código na linguagem `python`.

## Definições necessárias

Vamos começar pequeno, com uma única dimensão: suponha que você queira
estimar números `y = (y_0, y_1, ..., y_n)` (e.g. uma pontuação, um erro, uma quantidade) a partir de outros `x = (x_0, x_1, ..., x_n)`, mas não sabe exatamente como essas duas medidas se relacionam.

```python
import numpy as np

def dummy_dataset(n):
  r = np.random.rand
  return (np.asarray([i for i in range(n)]),
          np.asarray([n - i + 10 * r() for i in range(n)]))

x, y = dummy_dataset(1000)
```

O mais simples dos jeitos é um modelo linear:

<center>
<figure class="equation">
  <img src="/assets/ml/linear/linear.png" alt="Modelo de predição linear">
</figure>
</center>

```python
w0, b0 = np.random.rand(1), np.random.rand(1)

def model(x, w, b):
  return w.dot(x) + b

p0 = model(x, w0, b0)
print('predicoes iniciais:', p0)
print('predicoes esperadas:', y)
```

`w` e `b` são parâmetros, variáveis que afetam o comportamento de `p`.
Ao alterarmos `w` e `b`, podemos fazer com que `p` se torne mais próximo ou
mais distante da variável `y`. Pra isso, precisamos primeiro definir uma medida
-- comumente denominada *loss* --
que indique o quão distante um modelo `p` está da observação impírica `y`.
Uma *loss* comum é o *mean squared error* ou MSE:

<center>
<figure class="equation">
  <img src="/assets/ml/linear/mse.png" alt="MSE">
</figure>
</center>

```python
def mse(y, p):
  return ((p - y) ** 2).mean()
loss = mse

print('erro em treino inicial:', loss(y, p0))
```

## Treinamento

### Solução ótima

Minimizar `E(y, p)` significa aproximar os valores que saem do nosso
modelo linear ao valor real, mas como fazer isso? `p` é linear. Logo, `E` é uma
função quadrática positiva. O que significa que ela tem essa cara,
para qualquer um dos parâmetros envolvidos:

<center>
  <figure class="equation">
    <img src="/assets/ml/linear/squared-f.png" alt="Gráfico de uma função quadrática." style="width:100%; max-width:400px" />
  </figure>
</center>

Como podemos observar no gráfico acima, existe um único ponto crítico de
mínimo. Usando cálculo I, podemos calcular `w` e `b` que levam ao erro mínimo:

<center>
  <figure class="equation">
    <img src="/assets/ml/linear/optimal-weights.png" alt="Parâmetros ótimos"
         style="width:100%; max-width:800px" />
  </figure>
</center>

```python
def compute_optimal(w, b, x, y):
  p = model(x, w, b)
  de = (p - y)
  w_star = (de * (y - b) / x).mean(axis=0)
  b_star = (de * (y - w * x)).mean(axis=0)
  return w_star, b_star

w_star, b_star = compute_optimal(w, b, x, y)

p_star = model(x, w_star, b_star)
print('erro em treino otimo:', loss(y, p_star))
```

## Soluções iterativas

Muitas vezes, computar a solução ótima é computacionalmente infactível:

- o conjunto de dados é muito grande para caber na memória
- a operação `w*x + b` é muito demorada devido à grandeza das variáveis
- A função de erro possui mais de um mínimo (veremos este caso quando
  passarmos sobre modelos não-lineares)

Uma solução possível é executar o treinamento de forma iterativa, utilizando
o método chamado **Gradient Descent**.

### Online Stochastic Gradient Descent

Aqui, apresentamos cada amostra ao modelo e, logo em seguida, computamos
o gradiente.  
Já que o gradiente aponta para a direção de **maior aumento** da função `E`,
podemos reduzí-la ao somar `w` e `b` ao negativo de seus gradientes `-dw` e
`-db`. Desta forma, "caminhamos" para a região de **maior decremento** da funço
`E`. Isto é, a região de menor erro:

<center>
  <figure class="equation">
    <img src="/assets/ml/linear/iterative-loss-improvement.png"
         alt="Melhoramento iterativo de erro."
         style="width:100%; max-width:400px" />
  </figure>
</center>

Usualmente, escalamos a atualização por um fator `0 < lr <= 1` afim de
suavizar a modificação aplicada. Isto é importante visto que:

- somar gradientes de primeira ordem é fundalmentalmente um deslocamento
  em linha reta em uma função que é uma curva, representando simplesmente
  uma estimativa
- o gradiente leva em consideração uma única amostra e não o conjunto como
  um todo, sendo suscetível à *outliers*
  
O processo é repetido por diversas épocas, idealmente até a convergência.
Isto é, a estagnação do plano de decisão.

```python
def compute_gradients(xi, yi, wi, bi):
  pi = model(xi, wi, bi)
  de = (pi - yi)
  dw = de * xi
  db = de
  return dw, db

lr = 0.1
epochs = 100
w, b = w0, b0

for epoch in range(epochs):
  p = np.random.arange(samples)
  np.random.shuffle(p)
  x, y = x[p], y[p]

  for i, (_x, _y) in enumerate(zip(x, y)):
    _p = model(_x, w, b)
    _w, _b = compute_gradients(_p, _x, _y)
    w -= lr * _w
    b -= lr * _b
```

Uma característica importante do treinamento online é que ele rapidamente
reduz o MSE, já que computar `_x` é muito mais rápido do que `x`. Outra
é que ele frequentemente se materiraliza como um processo divergente,
já que o processo de atualização do modelo só enxerga uma única instância e
ignora as demais.

Podemos melhorar essa situação com um "meio termo". A estratégia de
**batches**.

### Mini-batch Gradient Descent

No treinamento por batches, um subconjunto de amostras **pequeno**, porém
**significativo** (que corretamente representa a distribuição dos dados de
  treinamento) é selecionado. O gradiente é então computado sobre o batch:

```python
samples = len(x)
batch_size = 128
batches = ceil(samples / batch_size)
w, b = w0, b0

for epoch in range(epochs):
  p = np.random.arange(samples)
  np.random.shuffle(p)
  x, y = x[p], y[p]
  
  for batch in range(batches):
    _x = x[batch * batch_size:(batch + 1) * batch_size]
    _y = y[batch * batch_size:(batch + 1) * batch_size]

    _p = model(_x, w, b)
    _w, _b = compute_gradients(_p, _x, _y)
    w -= lr * _w
    b -= lr * _b
```

A mais simples forma de induzir estabilidade na distribuição do batch é
através do que chamamos de **stochastic mini-batch gradient descent**,
onde as amostras são aleatóriamente selecionadas:

```python
for epoch in range(epochs):
  p = np.arange(samples)
  np.random.shuffle(p)
  x, y = x[p], y[p]

  for batch in range(batches):
    ...
```

Este (ou variações deste) é um dos método mais utilizados no treinamento
de redes neurais, atualmente.

## Teste

Os passos acima buscam o erro seja mínimo para as amostras de **treinamento**.
Entretanto, nosso objetivo não é criarmos um IF/ELSE gigante, que acerta todas
as amostras de treino mas erra terrívelmente para quaisquer amostras futuras.

Queremos que ele seja genérico o suficiente para ser reaplicado em situações
futuras, em amostras de **teste**. Portanto, usualmente subdividimos o conjunto
de dados em:
- **treino**: conjunto de amostras utilizadas para se atualizar os parâmetros do
              modelo.
- **teste**: conjunto de dados onde o modelo é aplicado e a *loss* registrada.
             Como o modelo não viu nenhuma destas amostras durante o treino,
             podemos supor que é assim que ele se comportará em amostras
             futuras.

Se existem hiper-parâmetros (`lr`, `batch_size`) ou se o treinamento é
iterativo, o conjunto de treino é normalmente separado em **treino** e
**validação**. Assim, modificamos os parâmetros com base nos gradientes
computado sobre as amostras de treino, mas mantemos o registro dos parâmetros
que resultarem menor erro nas amostras valiação. Isto é, estamos salvando os
parâmetros que **melhor generalizam** o problema.

```python
from sklearn.model_selection import train_test_split

train_size = 2 / 3
x, x_valid, y, y_valid = train_test_split(x, y, train_size=train_size)

for epoch in range(epochs):
  ... # Shuffle train set.
  for batch in range(batches):
    ... # Update gradients.

  p_valid = model(x_valid, w, b)
  if loss(y_valid, p_valid) <= best_valid_error:
    best_valid_error = loss(y_valid, p_valid)
    w_star, b_star = (w, b)
```

## Múltiplas características

Nenhum segredo aqui. Na verdade, todos os trechos de código escritos acima
já lidam com esse caso.

Com múltiplas características, uma amostra se torna um vetor de números e o
conjunto `x` uma matriz. Afim de garantir liberdade ao modelo, definimos `w`
também como um vetor, onde cada elemento é um coeficiente que multiplica um
atributo diferente. Portanto:

- Se `x` e `w` são números, há uma única característica e `dot` é a
  múltiplicação convencional nos Reais, resultando em um número
  que pode ser somado à `b`.
- Se `x` e `w` são vetores, `dot` é o produto interno, resultando em um número
  que pode ser somado à `b`.

O gradiente continua funcionando do mesmo jeito, já que `mean(axis=0)` garante
que somente a primeira dimensão (contendo a diferença entre amostras)
seja reduzida, preservando a diferença entre os diferentes parâmetros em
`w` (contidos na segunda dimensão).

## Um exemplo prático de regressão: Boston

Este conjunto de dados contém informações sobre casas na região metropolitana
de boston, relacionando atributos gerais ao custo de mercado efetivo destas.
Não sabemos exatamente como cada um desses atributos afetam o custo, mas podemos
usar um modelo linear para descobrir isso:

```python
import numpy as np

from sacred import Experiment

from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_boston
from sklearn.metrics import mean_squared_error as mse
from sklearn.model_selection import train_test_split

ex = Experiment('training-a-linear-regression-model')


@ex.config
def my_config():
  workers = 1
  test_size = 1/3
  split_random_state = 42


@ex.automain
def main(test_size, workers, split_random_state):
  dataset = load_boston()
  x_train, x_test, y_train, y_test = train_test_split(
      dataset.data, dataset.target,
      test_size=test_size,
      random_state=split_random_state)

  model = LinearRegression(n_jobs=workers)
  model.fit(x_train, y_train)

  print('train mse:', mse(y_train, model.predict(x_train)))
  print('test mse:', mse(y_test, model.predict(x_test)))

  print('y:', y_test)
  print('p:', model.predict(x_test))
```

```shell
INFO - training-a-linear-regression-model - Running command 'main'
INFO - training-a-linear-regression-model - Started
train mse: 23.0559695699
test mse: 20.6179622853
y: [ 23.60  32.40  13.60  22.80  16.10 ...]
p: [ 28.55  36.61  15.68  25.51  18.76 ...]
INFO - training-a-linear-regression-model - Completed after 0:00:00
```

MSE em teste está em 20.6k, o que significa que o modelo aproxima o preço verdadeiro `p` por uma margem de `(p - 4.54k, p + 4.54k)`.
Parece bom o suficiente pra mim. Por enquanto.

## Próximo post: não linearidade

Infelizmente, as coisas nem sempre serão resolvidas com retas e linearidade.
Resolver esses problemas exigem a utilização de modelos não-lineares, o que
envolve várias outras peculiaridades. Só para instigar, pense: o que aconteceria
com o erro se nosso modelo de decisão não fosse uma reta? O que acontece com
o espaço de otimização se existem multiplas características?

<center>
  <figure class="equation">
    <img src="/assets/ml/linear/nonlinear-f.png" alt="Gráfico de uma função não linear, de ordem superior à quadrática."
         style="width:100%; max-width:400px" />
  </figure>
</center>
